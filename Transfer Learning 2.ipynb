{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61f4eff6",
   "metadata": {},
   "source": [
    "# Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5579c885",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from skimage import io\n",
    "from os import listdir\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "%matplotlib inline\n",
    "import time\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e3bb752",
   "metadata": {},
   "source": [
    "### GPU testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ab1cb65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/GPU:0'):\n",
    "\n",
    "    print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b418093",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iter_sqrt(fname, num_iterations):\n",
    "    data = np.load(fname)\n",
    "    for i in range(num_iterations):\n",
    "        data = np.sqrt(data)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da510f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_func_stack(file_type_list,sqrt_scale,test_ratio):\n",
    "    \n",
    "    im_stack_plain = np.stack([iter_sqrt('np_data/NR_noise'+f+'.npy',s) if s \\\n",
    "                               else np.load('np_data/NR_noise'+f+'.npy') \\\n",
    "                               for f,s in zip(file_type_list,sqrt_scale)],axis=-1)\n",
    "    \n",
    "    im_stack = np.stack([iter_sqrt('np_data/Migdal_noise'+f+'.npy',s) if s \\\n",
    "                               else np.load('np_data/Migdal_noise'+f+'.npy') \\\n",
    "                               for f,s in zip(file_type_list,sqrt_scale)],axis=-1)\n",
    "    \n",
    "    e_stack = np.stack([iter_sqrt('np_data/Electron_noise'+f+'.npy',s) if s \\\n",
    "                               else np.load('np_data/Electron_noise'+f+'.npy') \\\n",
    "                               for f,s in zip(file_type_list,sqrt_scale)],axis=-1)\n",
    "    \n",
    "    not_mig = np.concatenate([im_stack_plain,e_stack])\n",
    "    \n",
    "    shuffle_index = np.arange(len(not_mig))\n",
    "    np.random.shuffle(shuffle_index)\n",
    "\n",
    "    not_mig_shuff = not_mig[shuffle_index]\n",
    "    new_not_mig = not_mig_shuff[:len(im_stack)]\n",
    "    \n",
    "    labels = np.concatenate([np.zeros_like(im_stack[:,0,0,0]),np.ones_like(new_not_mig[:,0,0,0])])\n",
    "    data = np.concatenate([im_stack,new_not_mig])\n",
    "\n",
    "    shuffle_index = np.arange(len(labels))\n",
    "    np.random.shuffle(shuffle_index)\n",
    "\n",
    "    labels = labels[shuffle_index]\n",
    "    data = data[shuffle_index]\n",
    "    \n",
    "    train_data_noise, test_data_noise, train_labels, test_labels = \\\n",
    "    train_test_split(data, labels, test_size=test_ratio, random_state=42)\n",
    "\n",
    "    del data, labels, im_stack_plain, im_stack, e_stack, not_mig, not_mig_shuff, new_not_mig, shuffle_index\n",
    "    \n",
    "    #loading the data into tf.data.Dataset objects\n",
    "    train_dataset_noise = tf.data.Dataset.from_tensor_slices((train_data_noise, train_labels)) \n",
    "    test_dataset_noise = tf.data.Dataset.from_tensor_slices((test_data_noise, test_labels))\n",
    "    # migdal_dataset_noise = tf.data.Dataset.from_tensor_slices((im_stack, np.zeros_like(energies)))\n",
    "    train_dataset_noise.element_spec\n",
    "\n",
    "    #batching the datasets\n",
    "    batch_size = 50\n",
    "    train_dataset_noise = train_dataset_noise.batch(batch_size)  # drop_remainder=True\n",
    "    test_dataset_noise = test_dataset_noise.batch(batch_size)\n",
    "    # migdal_dataset_noise = migdal_dataset_noise.batch(batch_size)\n",
    "    \n",
    "    del train_data_noise, test_data_noise, train_labels, test_labels\n",
    "    \n",
    "    return train_dataset_noise, test_dataset_noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e3d46814",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_type_list = ['_0.0_threshold', '_0.0_threshold', '_4.0_threshold']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf9ed5d",
   "metadata": {},
   "source": [
    "*Re-run from here*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d0524d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense, Conv2D, MaxPooling2D, LeakyReLU, Dropout\n",
    "\n",
    "def opt_model():\n",
    "    global file_type_list\n",
    "    opt_model = Sequential([\n",
    "        Conv2D(10, kernel_size=(3,3), input_shape=(150,150,len(file_type_list)), padding='same'),\n",
    "        LeakyReLU(),\n",
    "        MaxPooling2D(),\n",
    "        Conv2D(30, kernel_size=(3,3), padding='same'),\n",
    "        LeakyReLU(),\n",
    "        MaxPooling2D(),\n",
    "        Conv2D(30, kernel_size=(3,3), padding='same'),\n",
    "        LeakyReLU(),\n",
    "        MaxPooling2D(),\n",
    "        Flatten(),\n",
    "        Dropout(0.05),\n",
    "        Dense(20, kernel_regularizer = tf.keras.regularizers.L1L2(0.05,0.1)),\n",
    "        LeakyReLU(),\n",
    "        Dropout(0.05),\n",
    "        Dense(10, kernel_regularizer = tf.keras.regularizers.L1L2(0.05,0.1)),\n",
    "        LeakyReLU(),\n",
    "        Dense(1, activation='sigmoid'),\n",
    "    ], name='opt_model')\n",
    "    return opt_model\n",
    "\n",
    "model = opt_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a2e3d068",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-27 23:20:11.330784: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 8457480000 exceeds 10% of free system memory.\n",
      "2022-07-27 23:20:15.650455: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 8457480000 exceeds 10% of free system memory.\n",
      "2022-07-27 23:20:17.800050: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 8457480000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-27 23:20:20.287319: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2022-07-27 23:20:20.291043: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2099995000 Hz\n",
      "2022-07-27 23:20:20.510210: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2022-07-27 23:20:21.212054: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "314/314 [==============================] - 18s 38ms/step - loss: 38.0840 - accuracy: 0.7275 - val_loss: 6.1610 - val_accuracy: 0.7768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-27 23:20:37.481422: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 8457480000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/150\n",
      "314/314 [==============================] - 11s 34ms/step - loss: 5.2661 - accuracy: 0.7838 - val_loss: 3.6927 - val_accuracy: 0.7934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-27 23:20:50.248104: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 8457480000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/150\n",
      "314/314 [==============================] - 11s 34ms/step - loss: 3.3851 - accuracy: 0.7979 - val_loss: 2.8079 - val_accuracy: 0.8082\n",
      "Epoch 4/150\n",
      "314/314 [==============================] - 11s 34ms/step - loss: 2.6352 - accuracy: 0.8144 - val_loss: 2.1840 - val_accuracy: 0.8493\n",
      "Epoch 5/150\n",
      "314/314 [==============================] - 11s 35ms/step - loss: 2.1055 - accuracy: 0.8305 - val_loss: 1.8159 - val_accuracy: 0.8338\n",
      "Epoch 6/150\n",
      "314/314 [==============================] - 11s 35ms/step - loss: 1.7671 - accuracy: 0.8400 - val_loss: 1.6245 - val_accuracy: 0.8195\n",
      "Epoch 7/150\n",
      "314/314 [==============================] - 11s 35ms/step - loss: 1.5683 - accuracy: 0.8407 - val_loss: 1.4796 - val_accuracy: 0.8381\n",
      "Epoch 8/150\n",
      "314/314 [==============================] - 11s 35ms/step - loss: 1.4523 - accuracy: 0.8511 - val_loss: 1.3889 - val_accuracy: 0.8585\n",
      "Epoch 9/150\n",
      "314/314 [==============================] - 11s 35ms/step - loss: 1.4035 - accuracy: 0.8540 - val_loss: 1.3921 - val_accuracy: 0.8470\n",
      "Epoch 10/150\n",
      "314/314 [==============================] - 11s 35ms/step - loss: 1.3979 - accuracy: 0.8560 - val_loss: 1.3716 - val_accuracy: 0.8529\n",
      "Epoch 11/150\n",
      "314/314 [==============================] - 11s 36ms/step - loss: 1.3901 - accuracy: 0.8577 - val_loss: 1.3700 - val_accuracy: 0.8567\n",
      "Epoch 12/150\n",
      "314/314 [==============================] - 11s 34ms/step - loss: 1.3807 - accuracy: 0.8589 - val_loss: 1.3647 - val_accuracy: 0.8662\n",
      "Epoch 13/150\n",
      "314/314 [==============================] - 11s 34ms/step - loss: 1.3708 - accuracy: 0.8620 - val_loss: 1.3437 - val_accuracy: 0.8682\n",
      "Epoch 14/150\n",
      "314/314 [==============================] - 11s 34ms/step - loss: 1.3709 - accuracy: 0.8662 - val_loss: 1.3695 - val_accuracy: 0.8649\n",
      "Epoch 15/150\n",
      "314/314 [==============================] - 11s 34ms/step - loss: 1.3719 - accuracy: 0.8694 - val_loss: 1.3662 - val_accuracy: 0.8764\n",
      "Epoch 16/150\n",
      "314/314 [==============================] - 11s 34ms/step - loss: 1.3765 - accuracy: 0.8758 - val_loss: 1.3468 - val_accuracy: 0.8920\n",
      "Epoch 17/150\n",
      "314/314 [==============================] - 11s 34ms/step - loss: 1.3821 - accuracy: 0.8770 - val_loss: 1.3773 - val_accuracy: 0.8601\n",
      "Epoch 18/150\n",
      "314/314 [==============================] - 11s 34ms/step - loss: 1.3832 - accuracy: 0.8772 - val_loss: 1.3689 - val_accuracy: 0.8848\n",
      "Epoch 19/150\n",
      "314/314 [==============================] - 11s 34ms/step - loss: 1.3782 - accuracy: 0.8780 - val_loss: 1.3689 - val_accuracy: 0.8820\n",
      "Epoch 20/150\n",
      "314/314 [==============================] - 11s 34ms/step - loss: 1.3860 - accuracy: 0.8839 - val_loss: 1.4010 - val_accuracy: 0.8700\n",
      "Epoch 21/150\n",
      "314/314 [==============================] - 11s 34ms/step - loss: 1.3805 - accuracy: 0.8843 - val_loss: 1.4103 - val_accuracy: 0.8751\n",
      "Epoch 22/150\n",
      "314/314 [==============================] - 11s 34ms/step - loss: 1.4053 - accuracy: 0.8815 - val_loss: 1.3679 - val_accuracy: 0.8846\n",
      "Epoch 23/150\n",
      "314/314 [==============================] - 11s 34ms/step - loss: 1.3873 - accuracy: 0.8888 - val_loss: 1.3849 - val_accuracy: 0.8836\n",
      "Epoch 24/150\n",
      "314/314 [==============================] - 11s 34ms/step - loss: 1.3895 - accuracy: 0.8880 - val_loss: 1.3913 - val_accuracy: 0.8764\n",
      "Epoch 25/150\n",
      "314/314 [==============================] - 11s 34ms/step - loss: 1.4012 - accuracy: 0.8851 - val_loss: 1.3805 - val_accuracy: 0.8966\n",
      "Epoch 26/150\n",
      "314/314 [==============================] - 11s 34ms/step - loss: 1.3972 - accuracy: 0.8886 - val_loss: 1.3714 - val_accuracy: 0.8899\n",
      "Epoch 27/150\n",
      "314/314 [==============================] - 11s 34ms/step - loss: 1.3897 - accuracy: 0.8912 - val_loss: 1.3953 - val_accuracy: 0.8836\n",
      "Epoch 28/150\n",
      "314/314 [==============================] - 11s 34ms/step - loss: 1.3925 - accuracy: 0.8907 - val_loss: 1.3915 - val_accuracy: 0.8876\n",
      "Epoch 29/150\n",
      "314/314 [==============================] - 11s 34ms/step - loss: 1.3977 - accuracy: 0.8913 - val_loss: 1.4159 - val_accuracy: 0.8920\n",
      "Epoch 30/150\n",
      "314/314 [==============================] - 11s 34ms/step - loss: 1.4178 - accuracy: 0.8890 - val_loss: 1.3973 - val_accuracy: 0.8848\n",
      "Epoch 31/150\n",
      "314/314 [==============================] - 11s 34ms/step - loss: 1.3981 - accuracy: 0.8895 - val_loss: 1.3743 - val_accuracy: 0.8876\n",
      "Epoch 32/150\n",
      "314/314 [==============================] - 11s 34ms/step - loss: 1.3823 - accuracy: 0.8958 - val_loss: 1.4131 - val_accuracy: 0.8739\n",
      "Epoch 33/150\n",
      "314/314 [==============================] - 11s 34ms/step - loss: 1.3949 - accuracy: 0.8973 - val_loss: 1.4279 - val_accuracy: 0.8882\n",
      "Epoch 34/150\n",
      "314/314 [==============================] - 11s 34ms/step - loss: 1.4226 - accuracy: 0.8919 - val_loss: 1.4043 - val_accuracy: 0.8810\n",
      "Epoch 35/150\n",
      "314/314 [==============================] - 11s 34ms/step - loss: 1.4085 - accuracy: 0.8898 - val_loss: 1.3905 - val_accuracy: 0.8848\n",
      "Epoch 36/150\n",
      "314/314 [==============================] - 11s 34ms/step - loss: 1.3981 - accuracy: 0.8952 - val_loss: 1.3856 - val_accuracy: 0.8963\n",
      "Epoch 37/150\n",
      "314/314 [==============================] - 11s 34ms/step - loss: 1.4075 - accuracy: 0.8928 - val_loss: 1.4065 - val_accuracy: 0.8966\n",
      "Epoch 38/150\n",
      "314/314 [==============================] - 11s 34ms/step - loss: 1.3972 - accuracy: 0.8979 - val_loss: 1.4009 - val_accuracy: 0.8876\n",
      "Epoch 39/150\n",
      "314/314 [==============================] - 11s 34ms/step - loss: 1.4026 - accuracy: 0.8977 - val_loss: 1.3854 - val_accuracy: 0.8961\n",
      "Epoch 40/150\n",
      "314/314 [==============================] - 11s 34ms/step - loss: 1.4057 - accuracy: 0.8974 - val_loss: 1.4080 - val_accuracy: 0.8894\n",
      "Epoch 41/150\n",
      "314/314 [==============================] - 11s 34ms/step - loss: 1.3950 - accuracy: 0.8990 - val_loss: 1.4101 - val_accuracy: 0.8971\n",
      "Epoch 42/150\n",
      "314/314 [==============================] - 11s 34ms/step - loss: 1.3986 - accuracy: 0.8979 - val_loss: 1.4171 - val_accuracy: 0.8945\n",
      "Epoch 43/150\n",
      "314/314 [==============================] - 11s 34ms/step - loss: 1.4195 - accuracy: 0.8958 - val_loss: 1.4071 - val_accuracy: 0.8925\n",
      "Epoch 44/150\n",
      "314/314 [==============================] - 11s 34ms/step - loss: 1.3965 - accuracy: 0.8996 - val_loss: 1.4269 - val_accuracy: 0.8884\n",
      "Epoch 45/150\n",
      "314/314 [==============================] - 11s 34ms/step - loss: 1.4070 - accuracy: 0.8995 - val_loss: 1.4110 - val_accuracy: 0.8950\n",
      "Epoch 46/150\n",
      "314/314 [==============================] - 11s 34ms/step - loss: 1.3949 - accuracy: 0.8999 - val_loss: 1.4104 - val_accuracy: 0.8971\n",
      "Epoch 47/150\n",
      "314/314 [==============================] - 11s 34ms/step - loss: 1.4042 - accuracy: 0.9003 - val_loss: 1.4004 - val_accuracy: 0.8925\n",
      "Epoch 48/150\n",
      "314/314 [==============================] - 11s 34ms/step - loss: 1.4041 - accuracy: 0.9011 - val_loss: 1.3865 - val_accuracy: 0.9012\n",
      "Epoch 49/150\n",
      "314/314 [==============================] - 11s 34ms/step - loss: 1.3881 - accuracy: 0.8999 - val_loss: 1.4021 - val_accuracy: 0.8984\n",
      "Epoch 50/150\n",
      "314/314 [==============================] - 11s 34ms/step - loss: 1.3949 - accuracy: 0.9030 - val_loss: 1.4193 - val_accuracy: 0.8996\n",
      "Epoch 51/150\n",
      "314/314 [==============================] - 11s 34ms/step - loss: 1.3959 - accuracy: 0.9052 - val_loss: 1.4554 - val_accuracy: 0.8935\n",
      "Epoch 52/150\n",
      "314/314 [==============================] - 11s 34ms/step - loss: 1.4076 - accuracy: 0.8989 - val_loss: 1.4073 - val_accuracy: 0.9040\n",
      "Epoch 53/150\n",
      "314/314 [==============================] - 11s 34ms/step - loss: 1.3998 - accuracy: 0.9046 - val_loss: 1.4260 - val_accuracy: 0.8940\n",
      "Epoch 54/150\n",
      "314/314 [==============================] - 11s 34ms/step - loss: 1.4137 - accuracy: 0.9033 - val_loss: 1.4220 - val_accuracy: 0.8935\n",
      "Epoch 55/150\n",
      "314/314 [==============================] - 11s 34ms/step - loss: 1.3953 - accuracy: 0.9005 - val_loss: 1.4354 - val_accuracy: 0.8963\n",
      "Epoch 56/150\n",
      "314/314 [==============================] - 11s 34ms/step - loss: 1.4119 - accuracy: 0.9009 - val_loss: 1.3944 - val_accuracy: 0.8991\n",
      "Epoch 57/150\n",
      "314/314 [==============================] - 11s 34ms/step - loss: 1.3966 - accuracy: 0.9039 - val_loss: 1.4083 - val_accuracy: 0.9037\n",
      "Epoch 58/150\n",
      "314/314 [==============================] - 11s 34ms/step - loss: 1.3894 - accuracy: 0.9059 - val_loss: 1.4643 - val_accuracy: 0.9007\n",
      "Epoch 59/150\n",
      "314/314 [==============================] - 11s 34ms/step - loss: 1.4191 - accuracy: 0.9055 - val_loss: 1.4636 - val_accuracy: 0.8986\n",
      "Epoch 60/150\n",
      "314/314 [==============================] - 11s 34ms/step - loss: 1.4090 - accuracy: 0.9064 - val_loss: 1.3919 - val_accuracy: 0.9037\n",
      "Epoch 61/150\n",
      "314/314 [==============================] - 11s 35ms/step - loss: 1.3884 - accuracy: 0.9075 - val_loss: 1.4075 - val_accuracy: 0.8940\n",
      "Epoch 62/150\n",
      "314/314 [==============================] - 11s 34ms/step - loss: 1.3978 - accuracy: 0.9073 - val_loss: 1.4252 - val_accuracy: 0.9076\n",
      "Epoch 63/150\n",
      "314/314 [==============================] - 11s 34ms/step - loss: 1.4031 - accuracy: 0.9058 - val_loss: 1.4340 - val_accuracy: 0.9104\n",
      "Epoch 64/150\n",
      "314/314 [==============================] - 11s 34ms/step - loss: 1.4137 - accuracy: 0.9057 - val_loss: 1.4346 - val_accuracy: 0.8846\n",
      "Epoch 65/150\n",
      "314/314 [==============================] - 11s 35ms/step - loss: 1.3827 - accuracy: 0.9075 - val_loss: 1.4242 - val_accuracy: 0.9022\n",
      "Epoch 66/150\n",
      "314/314 [==============================] - 11s 35ms/step - loss: 1.3897 - accuracy: 0.9035 - val_loss: 1.3821 - val_accuracy: 0.9060\n",
      "Epoch 67/150\n",
      "314/314 [==============================] - 11s 34ms/step - loss: 1.3857 - accuracy: 0.9090 - val_loss: 1.4309 - val_accuracy: 0.9083\n",
      "Epoch 68/150\n",
      "314/314 [==============================] - 11s 34ms/step - loss: 1.4101 - accuracy: 0.9065 - val_loss: 1.4399 - val_accuracy: 0.8945\n",
      "Epoch 69/150\n",
      "314/314 [==============================] - 11s 34ms/step - loss: 1.3962 - accuracy: 0.9047 - val_loss: 1.3922 - val_accuracy: 0.9022\n",
      "Epoch 70/150\n",
      "314/314 [==============================] - 11s 34ms/step - loss: 1.4051 - accuracy: 0.9097 - val_loss: 1.4056 - val_accuracy: 0.9045\n",
      "Epoch 71/150\n",
      "314/314 [==============================] - 11s 34ms/step - loss: 1.3890 - accuracy: 0.9093 - val_loss: 1.4109 - val_accuracy: 0.9040\n",
      "Epoch 72/150\n",
      "314/314 [==============================] - 11s 34ms/step - loss: 1.3710 - accuracy: 0.9094 - val_loss: 1.4049 - val_accuracy: 0.9116\n",
      "Epoch 73/150\n",
      "314/314 [==============================] - 11s 34ms/step - loss: 1.3757 - accuracy: 0.9094 - val_loss: 1.3855 - val_accuracy: 0.9009\n",
      "Epoch 74/150\n",
      "314/314 [==============================] - 11s 34ms/step - loss: 1.3786 - accuracy: 0.9093 - val_loss: 1.4203 - val_accuracy: 0.9042\n",
      "Epoch 75/150\n",
      "314/314 [==============================] - 11s 34ms/step - loss: 1.3771 - accuracy: 0.9084 - val_loss: 1.4378 - val_accuracy: 0.8958\n",
      "Epoch 76/150\n",
      "314/314 [==============================] - 11s 34ms/step - loss: 1.3979 - accuracy: 0.9097 - val_loss: 1.4284 - val_accuracy: 0.9070\n",
      "Epoch 77/150\n",
      "314/314 [==============================] - 11s 34ms/step - loss: 1.3945 - accuracy: 0.9083 - val_loss: 1.4328 - val_accuracy: 0.8994\n",
      "Epoch 78/150\n",
      "314/314 [==============================] - 11s 34ms/step - loss: 1.3697 - accuracy: 0.9123 - val_loss: 1.3961 - val_accuracy: 0.9009\n",
      "Epoch 79/150\n",
      "314/314 [==============================] - 11s 34ms/step - loss: 1.3783 - accuracy: 0.9084 - val_loss: 1.4146 - val_accuracy: 0.9027\n",
      "Epoch 80/150\n",
      "314/314 [==============================] - 11s 34ms/step - loss: 1.3923 - accuracy: 0.9082 - val_loss: 1.4724 - val_accuracy: 0.8979\n",
      "Epoch 81/150\n",
      "314/314 [==============================] - 11s 34ms/step - loss: 1.4042 - accuracy: 0.9134 - val_loss: 1.4661 - val_accuracy: 0.8981\n",
      "Epoch 82/150\n",
      "314/314 [==============================] - 11s 34ms/step - loss: 1.4139 - accuracy: 0.9059 - val_loss: 1.4143 - val_accuracy: 0.9116\n",
      "Epoch 83/150\n",
      "314/314 [==============================] - 11s 34ms/step - loss: 1.3871 - accuracy: 0.9136 - val_loss: 1.4239 - val_accuracy: 0.9045\n",
      "Epoch 84/150\n",
      "314/314 [==============================] - 11s 34ms/step - loss: 1.3893 - accuracy: 0.9077 - val_loss: 1.4234 - val_accuracy: 0.9109\n",
      "Epoch 85/150\n",
      "314/314 [==============================] - 11s 34ms/step - loss: 1.3896 - accuracy: 0.9096 - val_loss: 1.4308 - val_accuracy: 0.9081\n",
      "Epoch 86/150\n",
      "314/314 [==============================] - 11s 34ms/step - loss: 1.3906 - accuracy: 0.9091 - val_loss: 1.4485 - val_accuracy: 0.8981\n",
      "Epoch 87/150\n",
      "314/314 [==============================] - 11s 34ms/step - loss: 1.3926 - accuracy: 0.9109 - val_loss: 1.4285 - val_accuracy: 0.8961\n",
      "Epoch 88/150\n",
      "314/314 [==============================] - 11s 34ms/step - loss: 1.4046 - accuracy: 0.9131 - val_loss: 1.4172 - val_accuracy: 0.9104\n",
      "Epoch 89/150\n",
      "314/314 [==============================] - 11s 34ms/step - loss: 1.3918 - accuracy: 0.9105 - val_loss: 1.4577 - val_accuracy: 0.9093\n",
      "Epoch 90/150\n",
      "314/314 [==============================] - 11s 34ms/step - loss: 1.4144 - accuracy: 0.9133 - val_loss: 1.4650 - val_accuracy: 0.9025\n",
      "Epoch 91/150\n",
      "314/314 [==============================] - 11s 34ms/step - loss: 1.3984 - accuracy: 0.9101 - val_loss: 1.4382 - val_accuracy: 0.9142\n",
      "Epoch 92/150\n",
      "314/314 [==============================] - 11s 34ms/step - loss: 1.4053 - accuracy: 0.9123 - val_loss: 1.4131 - val_accuracy: 0.9104\n",
      "Epoch 93/150\n",
      "314/314 [==============================] - 11s 34ms/step - loss: 1.3902 - accuracy: 0.9123 - val_loss: 1.4922 - val_accuracy: 0.8991\n",
      "Epoch 94/150\n",
      "314/314 [==============================] - 11s 34ms/step - loss: 1.4246 - accuracy: 0.9073 - val_loss: 1.4408 - val_accuracy: 0.9106\n",
      "Epoch 95/150\n",
      "314/314 [==============================] - 11s 34ms/step - loss: 1.3774 - accuracy: 0.9099 - val_loss: 1.4372 - val_accuracy: 0.8922\n",
      "Epoch 96/150\n",
      "314/314 [==============================] - 11s 34ms/step - loss: 1.3790 - accuracy: 0.9130 - val_loss: 1.4371 - val_accuracy: 0.8994\n",
      "Epoch 97/150\n",
      "314/314 [==============================] - 11s 34ms/step - loss: 1.3696 - accuracy: 0.9155 - val_loss: 1.4452 - val_accuracy: 0.9065\n",
      "Epoch 98/150\n",
      "314/314 [==============================] - 11s 34ms/step - loss: 1.3944 - accuracy: 0.9110 - val_loss: 1.4226 - val_accuracy: 0.8973\n",
      "Epoch 99/150\n",
      "314/314 [==============================] - 11s 34ms/step - loss: 1.3849 - accuracy: 0.9140 - val_loss: 1.4336 - val_accuracy: 0.9160\n",
      "Epoch 100/150\n",
      "314/314 [==============================] - 11s 34ms/step - loss: 1.3873 - accuracy: 0.9136 - val_loss: 1.4568 - val_accuracy: 0.8966\n",
      "Epoch 101/150\n",
      "314/314 [==============================] - 11s 34ms/step - loss: 1.4024 - accuracy: 0.9141 - val_loss: 1.4299 - val_accuracy: 0.9127\n",
      "Epoch 102/150\n",
      "314/314 [==============================] - 11s 34ms/step - loss: 1.3889 - accuracy: 0.9137 - val_loss: 1.4593 - val_accuracy: 0.9065\n",
      "Epoch 103/150\n",
      "314/314 [==============================] - 11s 34ms/step - loss: 1.4059 - accuracy: 0.9123 - val_loss: 1.4395 - val_accuracy: 0.8999\n",
      "Epoch 104/150\n",
      "314/314 [==============================] - 11s 34ms/step - loss: 1.4085 - accuracy: 0.9122 - val_loss: 1.4359 - val_accuracy: 0.9129\n",
      "Epoch 105/150\n",
      "314/314 [==============================] - 11s 34ms/step - loss: 1.4269 - accuracy: 0.9117 - val_loss: 1.4655 - val_accuracy: 0.9058\n",
      "Epoch 106/150\n",
      "314/314 [==============================] - 11s 34ms/step - loss: 1.3829 - accuracy: 0.9157 - val_loss: 1.4329 - val_accuracy: 0.9055\n",
      "Epoch 107/150\n",
      "314/314 [==============================] - 11s 34ms/step - loss: 1.3882 - accuracy: 0.9156 - val_loss: 1.4190 - val_accuracy: 0.9086\n",
      "Epoch 108/150\n",
      "314/314 [==============================] - 11s 34ms/step - loss: 1.3902 - accuracy: 0.9168 - val_loss: 1.4528 - val_accuracy: 0.9002\n",
      "Epoch 109/150\n",
      "314/314 [==============================] - 11s 34ms/step - loss: 1.3811 - accuracy: 0.9139 - val_loss: 1.4327 - val_accuracy: 0.9111\n",
      "Epoch 110/150\n",
      "314/314 [==============================] - 11s 34ms/step - loss: 1.3812 - accuracy: 0.9145 - val_loss: 1.4215 - val_accuracy: 0.9078\n",
      "Epoch 111/150\n",
      "314/314 [==============================] - 11s 34ms/step - loss: 1.3962 - accuracy: 0.9173 - val_loss: 1.4971 - val_accuracy: 0.9004\n",
      "Epoch 112/150\n",
      "314/314 [==============================] - 11s 34ms/step - loss: 1.3994 - accuracy: 0.9173 - val_loss: 1.4671 - val_accuracy: 0.8904\n",
      "Epoch 113/150\n",
      "314/314 [==============================] - 11s 34ms/step - loss: 1.4168 - accuracy: 0.9116 - val_loss: 1.5055 - val_accuracy: 0.8999\n",
      "Epoch 114/150\n",
      "314/314 [==============================] - 11s 34ms/step - loss: 1.3971 - accuracy: 0.9145 - val_loss: 1.4496 - val_accuracy: 0.9078\n",
      "Epoch 115/150\n",
      "314/314 [==============================] - 11s 34ms/step - loss: 1.4153 - accuracy: 0.9159 - val_loss: 1.4545 - val_accuracy: 0.9030\n",
      "Epoch 116/150\n",
      "314/314 [==============================] - 11s 34ms/step - loss: 1.4215 - accuracy: 0.9179 - val_loss: 1.4930 - val_accuracy: 0.8943\n",
      "Epoch 117/150\n",
      "314/314 [==============================] - 11s 34ms/step - loss: 1.3951 - accuracy: 0.9120 - val_loss: 1.4953 - val_accuracy: 0.9139\n",
      "Epoch 118/150\n",
      "314/314 [==============================] - 11s 34ms/step - loss: 1.4011 - accuracy: 0.9176 - val_loss: 1.4413 - val_accuracy: 0.9132\n",
      "Epoch 119/150\n",
      "314/314 [==============================] - 11s 34ms/step - loss: 1.3866 - accuracy: 0.9157 - val_loss: 1.4717 - val_accuracy: 0.9050\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f4f04157160>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset_noise, test_dataset_noise = data_func_stack(file_type_list,[0,1,0])\n",
    "\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', restore_best_weights=True, patience=20)\n",
    "\n",
    "model = opt_model()\n",
    "\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=opt, loss='binary_crossentropy',metrics=['accuracy'])\n",
    "model.fit(train_dataset_noise, epochs=150, validation_data=(test_dataset_noise),callbacks=[callback],\\\n",
    "         verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aae54f1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of Migdal events identified with cut of 0.001 = 779\n",
      "Accuracy with cut of 0.001 = 100.000%\n",
      "Total number of images tested: 3916\n",
      "Total number of actual Migdal events tested: 1955\n",
      "Number of Migdal events identified: 779\n",
      "Percentage of Migdal events identified correctly: 39.847%\n",
      "Number of false positive Migdal events: 0\n",
      "False-positive rate: 0%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "actual_label = []\n",
    "fp_indices = []\n",
    "migdals = 0\n",
    "\n",
    "cut = 0.001\n",
    "total = 0\n",
    "\n",
    "for tdn in test_dataset_noise:\n",
    "    data, labels = tdn\n",
    "    labels = labels.numpy().flatten()\n",
    "    batch_probs = model(data).numpy().flatten()\n",
    "    indices = np.where(batch_probs < cut)[0] #+ counter\n",
    "    actual_label.extend(list(labels[indices]))\n",
    "    migdals += len(labels[labels == 0])\n",
    "\n",
    "    fp_indices.extend(list(np.where((batch_probs < cut) & (labels == 1))[0] + total))\n",
    "\n",
    "    total += len(labels)\n",
    "\n",
    "test_list = [x for x in actual_label if x == 0]\n",
    "# del train_dataset_noise, test_dataset_noise, data, labels, batch_probs, indices\n",
    "print()\n",
    "print(f'Number of Migdal events identified with cut of {cut} = {len(actual_label)}')\n",
    "print(f'Accuracy with cut of {cut} = {(len(test_list)/len(actual_label)*100):.3f}%')\n",
    "print('Total number of images tested: '+str(total))\n",
    "print('Total number of actual Migdal events tested: '+str(migdals))\n",
    "print('Number of Migdal events identified: '+str(len(actual_label)))\n",
    "# print('Number of Migdal events missed: '+str(len([x for x in test_labels if x == 0])-len(test_list)))\n",
    "print(f'Percentage of Migdal events identified correctly: {(100*len(test_list)/migdals):.3f}%')\n",
    "print('Number of false positive Migdal events: '+str(len(actual_label)-len(test_list)))\n",
    "print(f'False-positive rate: {(100*(len(actual_label)-len(test_list))/(total-migdals)):.3g}%')\n",
    "# print('Computation time: --- %s seconds ---' % (time.time() - start_time))\n",
    "print()\n",
    "\n",
    "# fpr, acc = (100*(len(actual_label)-len(test_list))/(total-migdals)), (100*len(test_list)/migdals)\n",
    "# del start_time, model, actual_label, test_list, fp_indices, migdals, total, cut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9cedc078",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6622e0d",
   "metadata": {},
   "source": [
    "## Saving/Restoring Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fe880de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('tl_mod_1.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22454b16",
   "metadata": {},
   "source": [
    "Run from here when restarting session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bdfed1a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from skimage import io\n",
    "from os import listdir\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "%matplotlib inline\n",
    "import time\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense, Conv2D, MaxPooling2D, LeakyReLU, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8e39b38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "model = load_model(\"tl_mod_1.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d2498fde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "19cc6fc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"opt_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 150, 150, 10)      280       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)      (None, 150, 150, 10)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 75, 75, 10)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 75, 75, 30)        2730      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 75, 75, 30)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 37, 37, 30)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 37, 37, 30)        8130      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 37, 37, 30)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 18, 18, 30)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 9720)              0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 9720)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 20)                194420    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                210       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 205,781\n",
      "Trainable params: 205,781\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ee819bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(6):\n",
    "#     model.layers[i].trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4033d27a",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_type_list = ['_2.0_threshold', '_sub_bg', '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5b9fa943",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "118/118 [==============================] - 28s 171ms/step - loss: 46.1259 - accuracy: 0.6498 - val_loss: 3.8612 - val_accuracy: 0.7508\n",
      "Epoch 2/150\n",
      "118/118 [==============================] - 13s 108ms/step - loss: 3.4065 - accuracy: 0.7120 - val_loss: 2.2834 - val_accuracy: 0.7391\n",
      "Epoch 3/150\n",
      "118/118 [==============================] - 12s 106ms/step - loss: 2.7905 - accuracy: 0.6939 - val_loss: 3.8417 - val_accuracy: 0.7529\n",
      "Epoch 4/150\n",
      "118/118 [==============================] - 13s 107ms/step - loss: 5.1596 - accuracy: 0.7040 - val_loss: 4.0397 - val_accuracy: 0.6687\n",
      "Epoch 5/150\n",
      "118/118 [==============================] - 13s 107ms/step - loss: 3.3792 - accuracy: 0.7297 - val_loss: 2.3904 - val_accuracy: 0.7173\n",
      "Epoch 6/150\n",
      "118/118 [==============================] - 12s 106ms/step - loss: 2.3098 - accuracy: 0.7323 - val_loss: 1.8388 - val_accuracy: 0.7393\n",
      "Epoch 7/150\n",
      "118/118 [==============================] - 13s 107ms/step - loss: 1.9346 - accuracy: 0.7444 - val_loss: 1.8493 - val_accuracy: 0.7320\n",
      "Epoch 8/150\n",
      "118/118 [==============================] - 13s 107ms/step - loss: 1.7883 - accuracy: 0.7526 - val_loss: 1.7856 - val_accuracy: 0.7399\n",
      "Epoch 9/150\n",
      "118/118 [==============================] - 12s 106ms/step - loss: 1.9727 - accuracy: 0.7588 - val_loss: 1.7912 - val_accuracy: 0.7664\n",
      "Epoch 10/150\n",
      "118/118 [==============================] - 12s 106ms/step - loss: 1.8213 - accuracy: 0.7821 - val_loss: 2.0352 - val_accuracy: 0.7596\n",
      "Epoch 11/150\n",
      "118/118 [==============================] - 12s 106ms/step - loss: 1.8202 - accuracy: 0.8025 - val_loss: 1.8008 - val_accuracy: 0.7669\n",
      "Epoch 12/150\n",
      "118/118 [==============================] - 12s 106ms/step - loss: 1.7681 - accuracy: 0.8024 - val_loss: 1.8540 - val_accuracy: 0.7972\n",
      "Epoch 13/150\n",
      "118/118 [==============================] - 12s 106ms/step - loss: 1.7744 - accuracy: 0.8014 - val_loss: 3.3211 - val_accuracy: 0.7765\n",
      "Epoch 14/150\n",
      "118/118 [==============================] - 13s 107ms/step - loss: 10.7461 - accuracy: 0.7132 - val_loss: 16.2585 - val_accuracy: 0.4695\n",
      "Epoch 15/150\n",
      "118/118 [==============================] - 13s 108ms/step - loss: 11.5141 - accuracy: 0.6984 - val_loss: 3.2810 - val_accuracy: 0.7936\n",
      "Epoch 16/150\n",
      "118/118 [==============================] - 13s 107ms/step - loss: 2.8955 - accuracy: 0.7929 - val_loss: 2.0241 - val_accuracy: 0.8070\n",
      "Epoch 17/150\n",
      "118/118 [==============================] - 13s 107ms/step - loss: 1.9434 - accuracy: 0.8035 - val_loss: 1.6381 - val_accuracy: 0.8130\n",
      "Epoch 18/150\n",
      "118/118 [==============================] - 13s 107ms/step - loss: 1.6640 - accuracy: 0.8101 - val_loss: 1.9524 - val_accuracy: 0.8151\n",
      "Epoch 19/150\n",
      "118/118 [==============================] - 13s 109ms/step - loss: 1.7546 - accuracy: 0.8096 - val_loss: 1.5651 - val_accuracy: 0.8182\n",
      "Epoch 20/150\n",
      "118/118 [==============================] - 13s 108ms/step - loss: 1.6586 - accuracy: 0.8077 - val_loss: 1.6410 - val_accuracy: 0.8210\n",
      "Epoch 21/150\n",
      "118/118 [==============================] - 13s 107ms/step - loss: 1.6347 - accuracy: 0.8193 - val_loss: 2.2436 - val_accuracy: 0.7978\n",
      "Epoch 22/150\n",
      "118/118 [==============================] - 12s 106ms/step - loss: 2.0874 - accuracy: 0.8109 - val_loss: 1.7923 - val_accuracy: 0.8188\n",
      "Epoch 23/150\n",
      "118/118 [==============================] - 12s 106ms/step - loss: 1.7167 - accuracy: 0.8197 - val_loss: 1.6875 - val_accuracy: 0.8197\n",
      "Epoch 24/150\n",
      "118/118 [==============================] - 12s 106ms/step - loss: 1.6435 - accuracy: 0.8248 - val_loss: 1.6703 - val_accuracy: 0.8220\n",
      "Epoch 25/150\n",
      "118/118 [==============================] - 12s 106ms/step - loss: 1.7819 - accuracy: 0.8112 - val_loss: 1.5996 - val_accuracy: 0.8279\n",
      "Epoch 26/150\n",
      "118/118 [==============================] - 12s 106ms/step - loss: 1.6767 - accuracy: 0.8296 - val_loss: 1.5385 - val_accuracy: 0.8339\n",
      "Epoch 27/150\n",
      "118/118 [==============================] - 12s 106ms/step - loss: 1.6370 - accuracy: 0.8256 - val_loss: 1.5336 - val_accuracy: 0.8308\n",
      "Epoch 28/150\n",
      "118/118 [==============================] - 12s 106ms/step - loss: 1.6436 - accuracy: 0.8353 - val_loss: 1.4571 - val_accuracy: 0.8393\n",
      "Epoch 29/150\n",
      "118/118 [==============================] - 12s 106ms/step - loss: 1.5079 - accuracy: 0.8371 - val_loss: 1.6371 - val_accuracy: 0.8417\n",
      "Epoch 30/150\n",
      "118/118 [==============================] - 12s 106ms/step - loss: 1.6896 - accuracy: 0.8385 - val_loss: 1.6172 - val_accuracy: 0.8414\n",
      "Epoch 31/150\n",
      "118/118 [==============================] - 12s 106ms/step - loss: 1.6133 - accuracy: 0.8438 - val_loss: 1.5839 - val_accuracy: 0.8500\n",
      "Epoch 32/150\n",
      "118/118 [==============================] - 12s 106ms/step - loss: 1.6918 - accuracy: 0.8383 - val_loss: 1.5154 - val_accuracy: 0.8517\n",
      "Epoch 33/150\n",
      "118/118 [==============================] - 12s 106ms/step - loss: 1.5614 - accuracy: 0.8434 - val_loss: 1.6551 - val_accuracy: 0.8285\n",
      "Epoch 34/150\n",
      "118/118 [==============================] - 12s 106ms/step - loss: 1.5752 - accuracy: 0.8405 - val_loss: 1.5111 - val_accuracy: 0.8471\n",
      "Epoch 35/150\n",
      "118/118 [==============================] - 13s 107ms/step - loss: 1.5498 - accuracy: 0.8395 - val_loss: 1.4338 - val_accuracy: 0.8531\n",
      "Epoch 36/150\n",
      "118/118 [==============================] - 12s 106ms/step - loss: 1.5225 - accuracy: 0.8502 - val_loss: 1.6681 - val_accuracy: 0.8474\n",
      "Epoch 37/150\n",
      "118/118 [==============================] - 12s 106ms/step - loss: 1.6996 - accuracy: 0.8383 - val_loss: 1.6198 - val_accuracy: 0.8506\n",
      "Epoch 38/150\n",
      "118/118 [==============================] - 12s 106ms/step - loss: 1.6315 - accuracy: 0.8466 - val_loss: 1.4996 - val_accuracy: 0.8409\n",
      "Epoch 39/150\n",
      "118/118 [==============================] - 12s 106ms/step - loss: 1.5076 - accuracy: 0.8418 - val_loss: 1.7991 - val_accuracy: 0.8423\n",
      "Epoch 40/150\n",
      "118/118 [==============================] - 12s 106ms/step - loss: 1.9818 - accuracy: 0.8355 - val_loss: 1.5735 - val_accuracy: 0.8561\n",
      "Epoch 41/150\n",
      "118/118 [==============================] - 12s 106ms/step - loss: 1.6158 - accuracy: 0.8524 - val_loss: 1.5860 - val_accuracy: 0.8567\n",
      "Epoch 42/150\n",
      "118/118 [==============================] - 12s 106ms/step - loss: 1.5390 - accuracy: 0.8486 - val_loss: 1.5849 - val_accuracy: 0.8572\n",
      "Epoch 43/150\n",
      "118/118 [==============================] - 12s 106ms/step - loss: 1.5423 - accuracy: 0.8471 - val_loss: 1.5002 - val_accuracy: 0.8449\n",
      "Epoch 44/150\n",
      "118/118 [==============================] - 12s 106ms/step - loss: 1.4564 - accuracy: 0.8523 - val_loss: 1.5497 - val_accuracy: 0.8549\n",
      "Epoch 45/150\n",
      "118/118 [==============================] - 12s 105ms/step - loss: 1.5908 - accuracy: 0.8511 - val_loss: 1.5729 - val_accuracy: 0.8489\n",
      "Epoch 46/150\n",
      "118/118 [==============================] - 12s 106ms/step - loss: 1.5703 - accuracy: 0.8563 - val_loss: 1.4563 - val_accuracy: 0.8544\n",
      "Epoch 47/150\n",
      "118/118 [==============================] - 12s 106ms/step - loss: 1.5432 - accuracy: 0.8565 - val_loss: 1.4892 - val_accuracy: 0.8495\n",
      "Epoch 48/150\n",
      "118/118 [==============================] - 12s 106ms/step - loss: 1.4992 - accuracy: 0.8577 - val_loss: 1.5139 - val_accuracy: 0.8610\n",
      "Epoch 49/150\n",
      "118/118 [==============================] - 12s 106ms/step - loss: 1.5174 - accuracy: 0.8594 - val_loss: 1.4683 - val_accuracy: 0.8522\n",
      "Epoch 50/150\n",
      "118/118 [==============================] - 12s 106ms/step - loss: 1.4735 - accuracy: 0.8553 - val_loss: 1.4327 - val_accuracy: 0.8690\n",
      "Epoch 51/150\n",
      "118/118 [==============================] - 12s 106ms/step - loss: 1.5282 - accuracy: 0.8592 - val_loss: 1.4956 - val_accuracy: 0.8575\n",
      "Epoch 52/150\n",
      "118/118 [==============================] - 12s 106ms/step - loss: 1.4816 - accuracy: 0.8641 - val_loss: 1.4856 - val_accuracy: 0.8403\n",
      "Epoch 53/150\n",
      "118/118 [==============================] - 12s 105ms/step - loss: 1.4991 - accuracy: 0.8498 - val_loss: 1.5373 - val_accuracy: 0.8698\n",
      "Epoch 54/150\n",
      "118/118 [==============================] - 12s 105ms/step - loss: 1.5921 - accuracy: 0.8539 - val_loss: 1.6978 - val_accuracy: 0.8673\n",
      "Epoch 55/150\n",
      "118/118 [==============================] - 12s 106ms/step - loss: 1.6345 - accuracy: 0.8481 - val_loss: 1.6120 - val_accuracy: 0.8664\n",
      "Epoch 56/150\n",
      "118/118 [==============================] - 12s 106ms/step - loss: 1.6402 - accuracy: 0.8540 - val_loss: 1.8464 - val_accuracy: 0.8568\n",
      "Epoch 57/150\n",
      "118/118 [==============================] - 12s 106ms/step - loss: 1.7628 - accuracy: 0.8446 - val_loss: 1.8259 - val_accuracy: 0.8326\n",
      "Epoch 58/150\n",
      "118/118 [==============================] - 12s 106ms/step - loss: 1.7553 - accuracy: 0.8438 - val_loss: 2.1185 - val_accuracy: 0.8544\n",
      "Epoch 59/150\n",
      "118/118 [==============================] - 12s 106ms/step - loss: 2.2859 - accuracy: 0.8292 - val_loss: 1.9118 - val_accuracy: 0.8570\n",
      "Epoch 60/150\n",
      "118/118 [==============================] - 12s 106ms/step - loss: 1.7574 - accuracy: 0.8499 - val_loss: 1.6146 - val_accuracy: 0.8616\n",
      "Epoch 61/150\n",
      "118/118 [==============================] - 12s 106ms/step - loss: 1.7962 - accuracy: 0.8474 - val_loss: 2.2521 - val_accuracy: 0.8429\n",
      "Epoch 62/150\n",
      "118/118 [==============================] - 12s 106ms/step - loss: 2.1188 - accuracy: 0.8278 - val_loss: 1.5754 - val_accuracy: 0.8670\n",
      "Epoch 63/150\n",
      "118/118 [==============================] - 12s 106ms/step - loss: 1.5738 - accuracy: 0.8556 - val_loss: 1.7967 - val_accuracy: 0.8390\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f8524cca6a0>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset_noise, test_dataset_noise = data_func_stack(file_type_list,[1,0,0],0.7)\n",
    "\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', restore_best_weights=True, patience=10)\n",
    "\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=opt, loss='binary_crossentropy',metrics=['accuracy'])\n",
    "model.fit(train_dataset_noise, epochs=150, validation_data=(test_dataset_noise),callbacks=[callback],\\\n",
    "         verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "aa9d4a42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of Migdal events identified with cut of 0.08 = 3822\n",
      "Accuracy with cut of 0.08 = 98.796%\n",
      "Total number of images tested: 13705\n",
      "Total number of actual Migdal events tested: 6859\n",
      "Number of Migdal events identified: 3822\n",
      "Percentage of Migdal events identified correctly: 55.052%\n",
      "Number of false positive Migdal events: 46\n",
      "False-positive rate: 0.672%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "actual_label = []\n",
    "fp_indices = []\n",
    "migdals = 0\n",
    "\n",
    "cut = 0.08\n",
    "total = 0\n",
    "\n",
    "for tdn in test_dataset_noise:\n",
    "    data, labels = tdn\n",
    "    labels = labels.numpy().flatten()\n",
    "    batch_probs = model(data).numpy().flatten()\n",
    "    indices = np.where(batch_probs < cut)[0] #+ counter\n",
    "    actual_label.extend(list(labels[indices]))\n",
    "    migdals += len(labels[labels == 0])\n",
    "\n",
    "    fp_indices.extend(list(np.where((batch_probs < cut) & (labels == 1))[0] + total))\n",
    "\n",
    "    total += len(labels)\n",
    "\n",
    "test_list = [x for x in actual_label if x == 0]\n",
    "# del train_dataset_noise, test_dataset_noise, data, labels, batch_probs, indices\n",
    "print()\n",
    "print(f'Number of Migdal events identified with cut of {cut} = {len(actual_label)}')\n",
    "print(f'Accuracy with cut of {cut} = {(len(test_list)/len(actual_label)*100):.3f}%')\n",
    "print('Total number of images tested: '+str(total))\n",
    "print('Total number of actual Migdal events tested: '+str(migdals))\n",
    "print('Number of Migdal events identified: '+str(len(actual_label)))\n",
    "# print('Number of Migdal events missed: '+str(len([x for x in test_labels if x == 0])-len(test_list)))\n",
    "print(f'Percentage of Migdal events identified correctly: {(100*len(test_list)/migdals):.3f}%')\n",
    "print('Number of false positive Migdal events: '+str(len(actual_label)-len(test_list)))\n",
    "print(f'False-positive rate: {(100*(len(actual_label)-len(test_list))/(total-migdals)):.3g}%')\n",
    "# print('Computation time: --- %s seconds ---' % (time.time() - start_time))\n",
    "print()\n",
    "\n",
    "# fpr, acc = (100*(len(actual_label)-len(test_list))/(total-migdals)), (100*len(test_list)/migdals)\n",
    "# del start_time, model, actual_label, test_list, fp_indices, migdals, total, cut"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dd2cf42",
   "metadata": {},
   "source": [
    "# Re-trying same thing without transfer learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "55fcf42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense, Conv2D, MaxPooling2D, LeakyReLU, Dropout\n",
    "\n",
    "def opt_model():\n",
    "    global file_type_list\n",
    "    opt_model = Sequential([\n",
    "        Conv2D(10, kernel_size=(3,3), input_shape=(150,150,len(file_type_list)), padding='same'),\n",
    "        LeakyReLU(),\n",
    "        MaxPooling2D(),\n",
    "        Conv2D(30, kernel_size=(3,3), padding='same'),\n",
    "        LeakyReLU(),\n",
    "        MaxPooling2D(),\n",
    "        Conv2D(30, kernel_size=(3,3), padding='same'),\n",
    "        LeakyReLU(),\n",
    "        MaxPooling2D(),\n",
    "        Flatten(),\n",
    "        Dropout(0.05),\n",
    "        Dense(20, kernel_regularizer = tf.keras.regularizers.L1L2(0.05,0.1)),\n",
    "        LeakyReLU(),\n",
    "        Dropout(0.05),\n",
    "        Dense(10, kernel_regularizer = tf.keras.regularizers.L1L2(0.05,0.1)),\n",
    "        LeakyReLU(),\n",
    "        Dense(1, activation='sigmoid'),\n",
    "    ], name='opt_model')\n",
    "    return opt_model\n",
    "\n",
    "model = opt_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "751a3fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_type_list = ['_2.0_threshold', '_sub_bg', '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "976e1601",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-28 13:15:28.743870: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 7400700000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-28 13:15:33.590535: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2022-07-28 13:15:33.593951: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2099995000 Hz\n",
      "2022-07-28 13:15:33.783185: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2022-07-28 13:15:34.417746: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118/118 [==============================] - ETA: 0s - loss: 148.0394 - accuracy: 0.5900"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-28 13:15:42.448494: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 7400700000 exceeds 10% of free system memory.\n",
      "2022-07-28 13:15:44.200991: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 7400700000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118/118 [==============================] - 19s 113ms/step - loss: 147.6621 - accuracy: 0.5903 - val_loss: 54.0018 - val_accuracy: 0.7707\n",
      "Epoch 2/150\n",
      "117/118 [============================>.] - ETA: 0s - loss: 43.5274 - accuracy: 0.7136"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-28 13:15:55.752642: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 7400700000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118/118 [==============================] - 12s 106ms/step - loss: 43.3869 - accuracy: 0.7140 - val_loss: 22.0348 - val_accuracy: 0.7915\n",
      "Epoch 3/150\n",
      "118/118 [==============================] - 12s 106ms/step - loss: 18.7461 - accuracy: 0.7632 - val_loss: 11.5375 - val_accuracy: 0.8131\n",
      "Epoch 4/150\n",
      "118/118 [==============================] - 13s 107ms/step - loss: 10.4438 - accuracy: 0.7892 - val_loss: 7.7324 - val_accuracy: 0.8165\n",
      "Epoch 5/150\n",
      "118/118 [==============================] - 13s 107ms/step - loss: 7.2593 - accuracy: 0.7925 - val_loss: 5.9953 - val_accuracy: 0.7975\n",
      "Epoch 6/150\n",
      "118/118 [==============================] - 13s 108ms/step - loss: 5.7219 - accuracy: 0.8012 - val_loss: 5.0215 - val_accuracy: 0.8190\n",
      "Epoch 7/150\n",
      "118/118 [==============================] - 13s 108ms/step - loss: 4.8907 - accuracy: 0.8069 - val_loss: 4.4519 - val_accuracy: 0.8196\n",
      "Epoch 8/150\n",
      "118/118 [==============================] - 12s 106ms/step - loss: 4.3930 - accuracy: 0.8150 - val_loss: 4.1668 - val_accuracy: 0.8134\n",
      "Epoch 9/150\n",
      "118/118 [==============================] - 12s 106ms/step - loss: 4.1498 - accuracy: 0.8170 - val_loss: 3.9797 - val_accuracy: 0.8309\n",
      "Epoch 10/150\n",
      "118/118 [==============================] - 12s 107ms/step - loss: 3.9552 - accuracy: 0.8149 - val_loss: 3.8319 - val_accuracy: 0.8161\n",
      "Epoch 11/150\n",
      "118/118 [==============================] - 13s 107ms/step - loss: 3.7940 - accuracy: 0.8166 - val_loss: 3.6590 - val_accuracy: 0.8253\n",
      "Epoch 12/150\n",
      "118/118 [==============================] - 13s 107ms/step - loss: 3.6182 - accuracy: 0.8246 - val_loss: 3.5872 - val_accuracy: 0.8365\n",
      "Epoch 13/150\n",
      "118/118 [==============================] - 13s 108ms/step - loss: 3.5348 - accuracy: 0.8259 - val_loss: 3.3952 - val_accuracy: 0.8328\n",
      "Epoch 14/150\n",
      "118/118 [==============================] - 13s 108ms/step - loss: 3.4233 - accuracy: 0.8202 - val_loss: 3.7059 - val_accuracy: 0.8298\n",
      "Epoch 15/150\n",
      "118/118 [==============================] - 13s 107ms/step - loss: 3.4139 - accuracy: 0.8163 - val_loss: 3.2806 - val_accuracy: 0.8393\n",
      "Epoch 16/150\n",
      "118/118 [==============================] - 13s 107ms/step - loss: 3.2016 - accuracy: 0.8260 - val_loss: 3.2648 - val_accuracy: 0.7985\n",
      "Epoch 17/150\n",
      "118/118 [==============================] - 13s 107ms/step - loss: 3.2177 - accuracy: 0.8243 - val_loss: 2.9471 - val_accuracy: 0.8171\n",
      "Epoch 18/150\n",
      "118/118 [==============================] - 13s 107ms/step - loss: 3.0031 - accuracy: 0.8220 - val_loss: 2.8961 - val_accuracy: 0.8323\n",
      "Epoch 19/150\n",
      "118/118 [==============================] - 13s 107ms/step - loss: 2.8806 - accuracy: 0.8271 - val_loss: 2.7735 - val_accuracy: 0.8231\n",
      "Epoch 20/150\n",
      "118/118 [==============================] - 13s 108ms/step - loss: 2.7801 - accuracy: 0.8256 - val_loss: 2.7038 - val_accuracy: 0.8289\n",
      "Epoch 21/150\n",
      "118/118 [==============================] - 12s 106ms/step - loss: 2.6616 - accuracy: 0.8406 - val_loss: 2.6708 - val_accuracy: 0.8344\n",
      "Epoch 22/150\n",
      "118/118 [==============================] - 13s 108ms/step - loss: 2.5924 - accuracy: 0.8375 - val_loss: 2.4479 - val_accuracy: 0.8464\n",
      "Epoch 23/150\n",
      "118/118 [==============================] - 13s 107ms/step - loss: 2.5014 - accuracy: 0.8350 - val_loss: 2.4086 - val_accuracy: 0.8366\n",
      "Epoch 24/150\n",
      "118/118 [==============================] - 13s 107ms/step - loss: 2.4456 - accuracy: 0.8331 - val_loss: 2.3442 - val_accuracy: 0.8377\n",
      "Epoch 25/150\n",
      "118/118 [==============================] - 12s 106ms/step - loss: 2.3249 - accuracy: 0.8356 - val_loss: 2.3049 - val_accuracy: 0.8339\n",
      "Epoch 26/150\n",
      "118/118 [==============================] - 12s 106ms/step - loss: 2.2371 - accuracy: 0.8484 - val_loss: 2.1542 - val_accuracy: 0.8417\n",
      "Epoch 27/150\n",
      "118/118 [==============================] - 12s 105ms/step - loss: 2.1588 - accuracy: 0.8426 - val_loss: 2.1874 - val_accuracy: 0.8020\n",
      "Epoch 28/150\n",
      "118/118 [==============================] - 12s 105ms/step - loss: 2.1753 - accuracy: 0.8325 - val_loss: 2.0237 - val_accuracy: 0.8716\n",
      "Epoch 29/150\n",
      "118/118 [==============================] - 12s 105ms/step - loss: 2.0426 - accuracy: 0.8546 - val_loss: 1.9837 - val_accuracy: 0.8493\n",
      "Epoch 30/150\n",
      "118/118 [==============================] - 12s 106ms/step - loss: 2.0514 - accuracy: 0.8446 - val_loss: 1.9037 - val_accuracy: 0.8528\n",
      "Epoch 31/150\n",
      "118/118 [==============================] - 12s 106ms/step - loss: 1.9008 - accuracy: 0.8526 - val_loss: 1.9835 - val_accuracy: 0.8184\n",
      "Epoch 32/150\n",
      "118/118 [==============================] - 12s 107ms/step - loss: 1.9217 - accuracy: 0.8510 - val_loss: 1.7951 - val_accuracy: 0.8438\n",
      "Epoch 33/150\n",
      "118/118 [==============================] - 12s 105ms/step - loss: 1.8124 - accuracy: 0.8466 - val_loss: 1.7694 - val_accuracy: 0.8385\n",
      "Epoch 34/150\n",
      "118/118 [==============================] - 12s 106ms/step - loss: 1.7926 - accuracy: 0.8536 - val_loss: 1.7256 - val_accuracy: 0.8568\n",
      "Epoch 35/150\n",
      "118/118 [==============================] - 12s 106ms/step - loss: 1.7303 - accuracy: 0.8578 - val_loss: 1.7190 - val_accuracy: 0.8707\n",
      "Epoch 36/150\n",
      "118/118 [==============================] - 12s 106ms/step - loss: 1.6752 - accuracy: 0.8594 - val_loss: 1.6634 - val_accuracy: 0.8436\n",
      "Epoch 37/150\n",
      "118/118 [==============================] - 12s 106ms/step - loss: 1.6762 - accuracy: 0.8423 - val_loss: 1.6528 - val_accuracy: 0.8195\n",
      "Epoch 38/150\n",
      "118/118 [==============================] - 12s 106ms/step - loss: 1.6602 - accuracy: 0.8508 - val_loss: 1.5371 - val_accuracy: 0.8579\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f964c75c580>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset_noise, test_dataset_noise = data_func_stack(file_type_list,[1,0,0],0.7)\n",
    "\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', restore_best_weights=True, patience=10)\n",
    "\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=opt, loss='binary_crossentropy',metrics=['accuracy'])\n",
    "model.fit(train_dataset_noise, epochs=150, validation_data=(test_dataset_noise),callbacks=[callback],\\\n",
    "         verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0c26663e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of Migdal events identified with cut of 0.08 = 3538\n",
      "Accuracy with cut of 0.08 = 99.802%\n",
      "Total number of images tested: 13705\n",
      "Total number of actual Migdal events tested: 6784\n",
      "Number of Migdal events identified: 3538\n",
      "Percentage of Migdal events identified correctly: 52.049%\n",
      "Number of false positive Migdal events: 7\n",
      "False-positive rate: 0.101%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "actual_label = []\n",
    "fp_indices = []\n",
    "migdals = 0\n",
    "\n",
    "cut = 0.08\n",
    "total = 0\n",
    "\n",
    "for tdn in test_dataset_noise:\n",
    "    data, labels = tdn\n",
    "    labels = labels.numpy().flatten()\n",
    "    batch_probs = model(data).numpy().flatten()\n",
    "    indices = np.where(batch_probs < cut)[0] #+ counter\n",
    "    actual_label.extend(list(labels[indices]))\n",
    "    migdals += len(labels[labels == 0])\n",
    "\n",
    "    fp_indices.extend(list(np.where((batch_probs < cut) & (labels == 1))[0] + total))\n",
    "\n",
    "    total += len(labels)\n",
    "\n",
    "test_list = [x for x in actual_label if x == 0]\n",
    "# del train_dataset_noise, test_dataset_noise, data, labels, batch_probs, indices\n",
    "print()\n",
    "print(f'Number of Migdal events identified with cut of {cut} = {len(actual_label)}')\n",
    "print(f'Accuracy with cut of {cut} = {(len(test_list)/len(actual_label)*100):.3f}%')\n",
    "print('Total number of images tested: '+str(total))\n",
    "print('Total number of actual Migdal events tested: '+str(migdals))\n",
    "print('Number of Migdal events identified: '+str(len(actual_label)))\n",
    "# print('Number of Migdal events missed: '+str(len([x for x in test_labels if x == 0])-len(test_list)))\n",
    "print(f'Percentage of Migdal events identified correctly: {(100*len(test_list)/migdals):.3f}%')\n",
    "print('Number of false positive Migdal events: '+str(len(actual_label)-len(test_list)))\n",
    "print(f'False-positive rate: {(100*(len(actual_label)-len(test_list))/(total-migdals)):.3g}%')\n",
    "# print('Computation time: --- %s seconds ---' % (time.time() - start_time))\n",
    "print()\n",
    "\n",
    "# fpr, acc = (100*(len(actual_label)-len(test_list))/(total-migdals)), (100*len(test_list)/migdals)\n",
    "# del start_time, model, actual_label, test_list, fp_indices, migdals, total, cut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a37d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "local_vars = list(locals().items())\n",
    "for var, obj in local_vars:\n",
    "    print(var, sys.get)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
