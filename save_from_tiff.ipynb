{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "progress: 0.000%\n",
      "progress: 3.962%\n",
      "progress: 7.924%\n",
      "progress: 11.886%\n",
      "progress: 15.848%\n",
      "progress: 19.809%\n",
      "progress: 23.771%\n",
      "progress: 27.733%\n",
      "progress: 31.695%\n",
      "progress: 35.657%\n",
      "progress: 39.619%\n",
      "progress: 43.581%\n",
      "progress: 47.543%\n",
      "progress: 51.505%\n",
      "progress: 55.466%\n",
      "progress: 59.428%\n",
      "progress: 63.390%\n",
      "progress: 67.352%\n",
      "progress: 71.314%\n",
      "progress: 75.276%\n",
      "progress: 79.238%\n",
      "progress: 83.200%\n",
      "progress: 87.161%\n",
      "progress: 91.123%\n",
      "progress: 95.085%\n",
      "progress: 99.047%\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAD4CAYAAADrRI2NAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAQp0lEQVR4nO3df6zdd13H8eeLFspvt9l21raz1RTjZsKGtU6HChthhZF1/ywpEVPjTBMyDeAPbCXR8EeTAgb5x2kaQBv50VQYrNmirhYmMXEr3dhg3VZXWNkuLWuBIKBJpfPtH+fb7Gy7d/fHOafndJ/nI2nO9/s53+89r3t77+t+zvd8v+emqpAkteNF4w4gSTq3LH5JaozFL0mNsfglqTEWvyQ1ZvG4AwAsXbq01qxZM+4YknReuffee79TVcvmu99EFP+aNWs4dOjQuGNI0nklyTcXsp+HeiSpMRa/JDXG4pekxlj8ktQYi1+SGmPxS1JjLH5JaozFL0mNsfglqTETceXu+WrNtjsWvO+xndcNMYkkzZ0zfklqjMUvSY2x+CWpMRa/JDXG4pekxlj8ktQYi1+SGmPxS1JjLH5JaozFL0mNsfglqTEWvyQ1xuKXpMZY/JLUGItfkhozp+JPcizJ15Lcn+RQN3ZRkv1JHu1uL+zbfnuSo0mOJLl2VOElSfM3nxn/G6vq8qpa361vAw5U1TrgQLdOkkuBzcBlwEbgliSLhphZkjSAQQ71bAJ2d8u7gRv6xvdU1emqegw4CmwY4HEkSUM01+Iv4M4k9ybZ2o1dXFUnALrb5d34SuCJvn2nurFnSLI1yaEkh06dOrWw9JKkeZvr39y9qqqOJ1kO7E/yyPNsm2nG6jkDVbuAXQDr169/zv2SpNGY04y/qo53tyeBz9E7dPNkkhUA3e3JbvMpYHXf7quA48MKLEkazKzFn+QVSV51dhl4M/AgsA/Y0m22BbitW94HbE6yJMlaYB1wcNjBJUkLM5dDPRcDn0tydvtPVdU/J/kysDfJTcDjwI0AVXU4yV7gIeAMcHNVPTWS9JKkeZu1+KvqG8Brpxn/LnDNDPvsAHYMnE6SNHReuStJjbH4JakxFr8kNcbil6TGWPyS1BiLX5IaM9e3bJB0Hlmz7Y6B9j+287ohJdEksvilCTVoeUsz8VCPJDXG4pekxlj8ktQYi1+SGmPxS1JjLH5JaozFL0mNsfglqTEWvyQ1xuKXpMZY/JLUGItfkhpj8UtSYyx+SWqMxS9JjbH4JakxFr8kNcbil6TGWPyS1BiLX5IaY/FLUmPmXPxJFiX5SpLbu/WLkuxP8mh3e2HfttuTHE1yJMm1owguSVqY+cz43wU83Le+DThQVeuAA906SS4FNgOXARuBW5IsGk5cSdKg5lT8SVYB1wEf7RveBOzulncDN/SN76mq01X1GHAU2DCUtJKkgS2e43YfAd4LvKpv7OKqOgFQVSeSLO/GVwJ392031Y09Q5KtwFaASy65ZH6pJY3Umm13LHjfYzuvG2ISjcKsM/4kbwNOVtW9c/yYmWasnjNQtauq1lfV+mXLls3xQ0uSBjWXGf9VwPVJ3gq8FHh1kk8ATyZZ0c32VwAnu+2ngNV9+68Cjg8ztCRp4Wad8VfV9qpaVVVr6L1o+4WqegewD9jSbbYFuK1b3gdsTrIkyVpgHXBw6MklSQsy12P809kJ7E1yE/A4cCNAVR1Oshd4CDgD3FxVTw2cVJI0FPMq/qq6C7irW/4ucM0M2+0AdgyYTZI0Al65K0mNsfglqTGDHOPXADxPWtK4OOOXpMZY/JLUGItfkhpj8UtSYyx+SWqMxS9JjbH4JakxFr8kNcbil6TGWPyS1BiLX5IaY/FLUmMsfklqjMUvSY2x+CWpMRa/JDXG4pekxlj8ktQYi1+SGmPxS1JjLH5JaozFL0mNWTzuAOO2Ztsd444gSeeUM35JaozFL0mNmbX4k7w0ycEkDyQ5nOT93fhFSfYnebS7vbBvn+1JjiY5kuTaUX4CkqT5mcuM/zRwdVW9Frgc2JjkSmAbcKCq1gEHunWSXApsBi4DNgK3JFk0guySpAWYtfir50fd6ou7fwVsAnZ347uBG7rlTcCeqjpdVY8BR4ENwwwtSVq4OR3jT7Ioyf3ASWB/Vd0DXFxVJwC62+Xd5iuBJ/p2n+rGnv0xtyY5lOTQqVOnBvgUJEnzMafir6qnqupyYBWwIckvPs/mme5DTPMxd1XV+qpav2zZsjmFlSQNbl5n9VTV94G76B27fzLJCoDu9mS32RSwum+3VcDxQYNKkoZjLmf1LEtyQbf8MuBNwCPAPmBLt9kW4LZueR+wOcmSJGuBdcDBIeeWJC3QXK7cXQHs7s7MeRGwt6puT/IfwN4kNwGPAzcCVNXhJHuBh4AzwM1V9dRo4kuS5mvW4q+qrwJXTDP+XeCaGfbZAewYOJ0kaei8cleSGtP8m7SdjwZ9Y7ljO68bUhJJ5yNn/JLUGItfkhpj8UtSYyx+SWqMxS9JjbH4JakxFr8kNcbil6TGWPyS1BiLX5IaY/FLUmMsfklqjMUvSY2x+CWpMRa/JDXG4pekxviHWCQN1SB/KMg/EnRuOOOXpMZY/JLUGItfkhpj8UtSYyx+SWqMxS9JjfF0zgZ5up3UNmf8ktQYi1+SGmPxS1JjZi3+JKuTfDHJw0kOJ3lXN35Rkv1JHu1uL+zbZ3uSo0mOJLl2lJ+AJGl+5jLjPwP8UVX9AnAlcHOSS4FtwIGqWgcc6Nbp7tsMXAZsBG5JsmgU4SVJ8zdr8VfViaq6r1v+IfAwsBLYBOzuNtsN3NAtbwL2VNXpqnoMOApsGHJuSdICzesYf5I1wBXAPcDFVXUCer8cgOXdZiuBJ/p2m+rGnv2xtiY5lOTQqVOnFhBdkrQQcy7+JK8EPgu8u6p+8HybTjNWzxmo2lVV66tq/bJly+YaQ5I0oDldwJXkxfRK/5NVdWs3/GSSFVV1IskK4GQ3PgWs7tt9FXB8WIGl88kgF8tJozKXs3oCfAx4uKo+3HfXPmBLt7wFuK1vfHOSJUnWAuuAg8OLLEkaxFxm/FcBvw18Lcn93difATuBvUluAh4HbgSoqsNJ9gIP0Tsj6OaqemrYwSVJCzNr8VfVvzP9cXuAa2bYZwewY4BckqQR8cpdSWqMxS9JjbH4JakxFr8kNcbil6TGWPyS1BiLX5IaY/FLUmMsfklqjMUvSY2x+CWpMRa/JDXG4pekxlj8ktQYi1+SGmPxS1JjLH5JaozFL0mNsfglqTEWvyQ1xuKXpMZY/JLUGItfkhpj8UtSYyx+SWqMxS9JjbH4JakxFr8kNWbW4k/y8SQnkzzYN3ZRkv1JHu1uL+y7b3uSo0mOJLl2VMElSQszlxn/3wMbnzW2DThQVeuAA906SS4FNgOXdfvckmTR0NJKkgY2a/FX1ZeA7z1reBOwu1veDdzQN76nqk5X1WPAUWDDcKJKkoZh8QL3u7iqTgBU1Ykky7vxlcDdfdtNdWPPkWQrsBXgkksuWWAMnWtrtt2x4H2P7bxuiEkkLdSwX9zNNGM13YZVtauq1lfV+mXLlg05hiRpJgud8T+ZZEU3218BnOzGp4DVfdutAo4PElAat0Ge5UiTaKEz/n3Alm55C3Bb3/jmJEuSrAXWAQcHiyhJGqZZZ/xJPg28AViaZAr4C2AnsDfJTcDjwI0AVXU4yV7gIeAMcHNVPTWi7JKkBZi1+Kvq7TPcdc0M2+8AdgwSSpI0Ol65K0mNsfglqTEWvyQ1xuKXpMYs9Dx+ad686leaDM74JakxFr8kNcbil6TGWPyS1Bhf3JU0MTwB4Nxwxi9JjbH4JakxFr8kNeYFcYzfP5QhSXPnjF+SGvOCmPFLs/FZofQ0Z/yS1BiLX5IaY/FLUmM8xq/zgsfopeFxxi9JjbH4JakxFr8kNcbil6TGWPyS1BjP6pH0guB7+c+dM35JaozFL0mNsfglqTEjK/4kG5McSXI0ybZRPY4kaX5GUvxJFgF/DbwFuBR4e5JLR/FYkqT5GdVZPRuAo1X1DYAke4BNwEMjejxJWrBxvhfUOM4oGlXxrwSe6FufAn6lf4MkW4Gt3eqPkhzplpcC3xlRrmEx4/CcDznNOBxmnEY+MO9d+jP+zEIec1TFn2nG6hkrVbuAXc/ZMTlUVetHlGsozDg850NOMw6HGYdjGBlH9eLuFLC6b30VcHxEjyVJmodRFf+XgXVJ1iZ5CbAZ2Deix5IkzcNIDvVU1Zkkvw/8C7AI+HhVHZ7j7s85/DOBzDg850NOMw6HGYdj4Iypqtm3kiS9YHjlriQ1xuKXpMaMtfiTrE7yxSQPJzmc5F3d+EVJ9id5tLu9cMw5FyX5SpLbJzFfl+mCJJ9J8kj39fzVScuZ5D3d//ODST6d5KXjzpjk40lOJnmwb2zGTEm2d29DciTJtWPM+KHu//qrST6X5IJxZpwpZ999f5ykkiwdZ86ZMib5gy7H4SQfnLSMSS5PcneS+5McSrJhoIxVNbZ/wArgdd3yq4D/pPcWDx8EtnXj24APjDnnHwKfAm7v1icqX5djN/B73fJLgAsmKSe9i/oeA17Wre8FfmfcGYHfAF4HPNg3Nm2m7nvzAWAJsBb4OrBoTBnfDCzulj8w7owz5ezGV9M70eObwNIJ/Fq+EfhXYEm3vnwCM94JvKVbfitw1yAZxzrjr6oTVXVft/xD4GF6BbGJXpHR3d4wloBAklXAdcBH+4YnJh9AklfT+2b5GEBV/W9VfZ8Jy0nvLLKXJVkMvJzetR1jzVhVXwK+96zhmTJtAvZU1emqegw4Su/tSc55xqq6s6rOdKt307tWZmwZZ8rZ+SvgvTzzIs6J+VoC7wR2VtXpbpuTE5ixgFd3yz/B09dFLSjjxBzjT7IGuAK4B7i4qk5A75cDsHyM0T5C75v2//rGJikfwM8Cp4C/6w5JfTTJK5ignFX1LeAvgceBE8B/VdWdk5Sxz0yZpnsrkpXnONt0fhf4p255ojImuR74VlU98Ky7Jinna4BfT3JPkn9L8svd+CRlfDfwoSRP0Ps52t6NLyjjRBR/klcCnwXeXVU/GHees5K8DThZVfeOO8ssFtN7avg3VXUF8N/0DlFMjO44+SZ6T0d/GnhFkneMN9W8zfpWJOdakvcBZ4BPnh2aZrOxZEzycuB9wJ9Pd/c0Y+P6Wi4GLgSuBP4E2JskTFbGdwLvqarVwHvont2zwIxjL/4kL6ZX+p+sqlu74SeTrOjuXwGcnGn/EbsKuD7JMWAPcHWST0xQvrOmgKmquqdb/wy9XwSTlPNNwGNVdaqqfgzcCvzahGU8a6ZME/VWJEm2AG8Dfqu6A75MVsafo/eL/oHuZ2gVcF+Sn2Kyck4Bt1bPQXrP7pcyWRm30PuZAfhHnj6cs6CM4z6rJ/R+cz1cVR/uu2sfvU+U7va2c50NoKq2V9WqqlpD720nvlBV75iUfGdV1beBJ5L8fDd0Db23wJ6knI8DVyZ5eff/fg2913QmKeNZM2XaB2xOsiTJWmAdcHAM+UiyEfhT4Pqq+p++uyYmY1V9raqWV9Wa7mdoit7JHN+epJzA54GrAZK8ht7JEd+ZsIzHgd/slq8GHu2WF5Zx1K9Qz/Lq9evpPS35KnB/9++twE8CB7pP7gBw0ThzdlnfwNNn9UxivsuBQ93X8vP0nrpOVE7g/cAjwIPAP9A7E2GsGYFP03vN4cf0iumm58tE79DF14EjdGdZjCnjUXrHds/+3PztODPOlPNZ9x+jO6tnwr6WLwE+0X1f3gdcPYEZXw/cS+8MnnuAXxoko2/ZIEmNGfsxfknSuWXxS1JjLH5JaozFL0mNsfglqTEWvyQ1xuKXpMb8P+mmdGAhMFk8AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from skimage import io\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "%matplotlib inline\n",
    "\n",
    "from os import listdir\n",
    "\n",
    "NR_directory = '/vols/lz/lshanahan/data/DD/'\n",
    "migdal_directory = '/vols/lz/lshanahan/data/DD_migdal/'\n",
    "e_directory = '/vols/lz/lshanahan/data/e/'\n",
    "\n",
    "\n",
    "NR_files = [f'{NR_directory}{f}' for f in listdir(NR_directory)]\n",
    "migdal_files = [f'{migdal_directory}{f}' for f in listdir(migdal_directory)]\n",
    "e_files = [f'{e_directory}{f}' for f in listdir(e_directory)]\n",
    "\n",
    "all_files = NR_files + migdal_files + e_files\n",
    "\n",
    "random.shuffle(all_files)\n",
    "\n",
    "labels = np.asarray([0 if f.startswith(migdal_directory) else 1 for f in all_files])\n",
    "\n",
    "\n",
    "long_files = [f for f in migdal_files if ((f[len(migdal_directory)] == \"6\") and (f[len(migdal_directory)+3] == \".\"))]\n",
    "\n",
    "widths = np.zeros((len(long_files),2))\n",
    "for i,f in enumerate(long_files):\n",
    "    if i%(len(long_files)//25) == 0:\n",
    "        print(f'progress: {(100*i/len(long_files)):.3f}%')\n",
    "    im = io.imread(f)\n",
    "    im = im[::2,::2] + im[1::2,::2] + im[::2,1::2] + im[1::2,1::2]\n",
    "#     print(f)\n",
    "\n",
    "    imsum_y = np.sum(im,axis=0)\n",
    "    width_y = len(imsum_y[imsum_y>0])\n",
    "    imsum_x = np.sum(im,axis=1)\n",
    "    width_x = len(imsum_x[imsum_x>0])\n",
    "    \n",
    "    widths[i,:] = width_x,width_y\n",
    "   \n",
    "\n",
    "plt.figure()\n",
    "plt.hist(widths.flatten(),bins=20)\n",
    "\n",
    "max_width = np.max(widths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pickle.dump(all_files, open( \"all_files.p\", \"wb\" ) )\n",
    "np.save('labels',labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Group 0 progress: 0.000%\n",
      "Group 0 progress: 20.000%\n",
      "Group 0 progress: 40.000%\n",
      "Group 0 progress: 60.000%\n",
      "Group 0 progress: 80.000%\n",
      "\n",
      "Group 1 progress: 0.000%\n",
      "Group 1 progress: 20.000%\n",
      "Group 1 progress: 40.000%\n",
      "Group 1 progress: 60.000%\n",
      "Group 1 progress: 80.000%\n",
      "\n",
      "Group 2 progress: 0.000%\n",
      "Group 2 progress: 20.000%\n",
      "Group 2 progress: 40.000%\n",
      "Group 2 progress: 60.000%\n",
      "Group 2 progress: 80.000%\n",
      "\n",
      "Group 3 progress: 0.000%\n",
      "Group 3 progress: 20.000%\n",
      "Group 3 progress: 40.000%\n",
      "Group 3 progress: 60.000%\n",
      "Group 3 progress: 80.000%\n",
      "\n",
      "Group 4 progress: 0.000%\n",
      "Group 4 progress: 20.000%\n",
      "Group 4 progress: 40.000%\n",
      "Group 4 progress: 60.000%\n",
      "Group 4 progress: 80.000%\n",
      "\n",
      "Group 5 progress: 0.000%\n",
      "Group 5 progress: 20.000%\n",
      "Group 5 progress: 40.000%\n",
      "Group 5 progress: 60.000%\n",
      "Group 5 progress: 80.000%\n",
      "\n",
      "Group 6 progress: 0.000%\n",
      "Group 6 progress: 20.000%\n",
      "Group 6 progress: 40.000%\n",
      "Group 6 progress: 60.000%\n",
      "Group 6 progress: 80.000%\n",
      "\n",
      "Group 7 progress: 0.000%\n",
      "Group 7 progress: 20.000%\n",
      "Group 7 progress: 40.000%\n",
      "Group 7 progress: 60.000%\n",
      "Group 7 progress: 80.000%\n",
      "\n",
      "Group 8 progress: 0.000%\n",
      "Group 8 progress: 20.000%\n",
      "Group 8 progress: 40.000%\n",
      "Group 8 progress: 60.000%\n",
      "Group 8 progress: 80.000%\n",
      "\n",
      "Group 9 progress: 0.000%\n",
      "Group 9 progress: 20.000%\n",
      "Group 9 progress: 40.000%\n",
      "Group 9 progress: 60.000%\n",
      "Group 9 progress: 80.000%\n",
      "\n",
      "Group 10 progress: 0.000%\n",
      "Group 10 progress: 20.000%\n",
      "Group 10 progress: 40.000%\n",
      "Group 10 progress: 60.000%\n",
      "Group 10 progress: 80.000%\n",
      "\n",
      "Group 11 progress: 0.000%\n",
      "Group 11 progress: 20.000%\n",
      "Group 11 progress: 40.000%\n",
      "Group 11 progress: 60.000%\n",
      "Group 11 progress: 80.000%\n",
      "\n",
      "Group 12 progress: 0.000%\n",
      "Group 12 progress: 20.000%\n",
      "Group 12 progress: 40.000%\n",
      "Group 12 progress: 60.000%\n",
      "Group 12 progress: 80.000%\n",
      "\n",
      "Group 13 progress: 0.000%\n",
      "Group 13 progress: 20.000%\n",
      "Group 13 progress: 40.000%\n",
      "Group 13 progress: 60.000%\n",
      "Group 13 progress: 80.000%\n"
     ]
    }
   ],
   "source": [
    "all_files = pickle.load( open( \"all_files.p\", \"rb\" ) )\n",
    "labels = np.load('labels.npy')\n",
    "\n",
    "save_dir = '/vols/lz/lshanahan/data/numpy/'\n",
    "group_size = 3000\n",
    "max_width = int(max_width)\n",
    "\n",
    "for i in range(0*group_size, 14*group_size, group_size): # looping over groups\n",
    "    labels_group = labels[i:(i+group_size)]\n",
    "    data_list = []\n",
    "    energies = np.asarray([float(f.split('k')[0].split('/')[-1]) for f in all_files[i:(i+group_size)]])\n",
    "    im_stack = np.zeros((len(labels_group),max_width+10,max_width+10))\n",
    "    keep_data = np.ones(len(labels_group),dtype=bool)\n",
    "    print()\n",
    "    for j in range(i, i+group_size): # looping over elements of group\n",
    "        if (j-i)%(len(labels_group)//5) == 0:\n",
    "            print(f'Group {i//group_size} progress: {(100*(j-i)/len(labels_group)):.3f}%')\n",
    "        \n",
    "        im = io.imread(all_files[j])\n",
    "        im = im[::2,::2] + im[1::2,::2] + im[::2,1::2] + im[1::2,1::2]\n",
    "        imsum_x = np.sum(im,axis=1)\n",
    "        imsum_y = np.sum(im,axis=0)\n",
    "        try:\n",
    "            min_x = np.where(imsum_x>0)[0][0]\n",
    "            min_y = np.where(imsum_y>0)[0][0]\n",
    "        except:\n",
    "            keep_data[j-i] = False\n",
    "            continue\n",
    "\n",
    "        if min_x > 5:\n",
    "            min_x -= 5\n",
    "        else:\n",
    "            min_x = 0\n",
    "\n",
    "        if min_y > 5:\n",
    "            min_y -= 5\n",
    "        else:\n",
    "            min_y = 0\n",
    "\n",
    "        im_slice = im[min_x:(min_x+max_width+10),min_y:(min_y+max_width+10)]\n",
    "        im_stack[(j-i),:im_slice.shape[0],:im_slice.shape[1]] = im_slice\n",
    "\n",
    "    np.save(f'{save_dir}data_{int(i//group_size)}', im_stack[keep_data,:,:])\n",
    "    np.save(f'{save_dir}labels_{int(i//group_size)}', labels_group[keep_data])\n",
    "    np.save(f'{save_dir}energies_{int(i//group_size)}', energies[keep_data])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from skimage import io\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "%matplotlib inline\n",
    "\n",
    "from os import listdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3000, 184, 184)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "load_dir = '/vols/lz/lshanahan/data/numpy/'\n",
    "files = listdir(load_dir)\n",
    "\n",
    "test = np.load(f'{load_dir}/data_1.npy')/20\n",
    "\n",
    "print(test.shape)\n",
    "\n",
    "plt.imshow(test[1],cmap='jet');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 1152, 1152)\n",
      "(1000, 576, 576)\n"
     ]
    }
   ],
   "source": [
    "avg_bg = np.load('../fast_2x2_bg.npy')\n",
    "avg_noise = np.load(\"../fast_2x2_noise.npy\")\n",
    "\n",
    "noise = np.stack([io.imread(\"../bg/\"+im) for im in listdir('../bg/')],axis=0)\n",
    "\n",
    "print(noise.shape)\n",
    "\n",
    "noise = noise[:,::2,::2] + noise[:,1::2,::2] + noise[:,::2,1::2] + noise[:,1::2,1::2]\n",
    "\n",
    "print(noise.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "progress: 0.000%\n",
      "progress: 2.778%\n",
      "progress: 5.556%\n",
      "progress: 8.333%\n",
      "progress: 11.111%\n",
      "progress: 13.889%\n",
      "progress: 16.667%\n",
      "progress: 19.444%\n",
      "progress: 22.222%\n",
      "progress: 25.000%\n",
      "progress: 27.778%\n",
      "progress: 30.556%\n",
      "progress: 33.333%\n",
      "progress: 36.111%\n",
      "progress: 38.889%\n",
      "progress: 41.667%\n",
      "progress: 44.444%\n",
      "progress: 47.222%\n",
      "progress: 50.000%\n",
      "progress: 52.778%\n",
      "progress: 55.556%\n",
      "progress: 58.333%\n",
      "progress: 61.111%\n",
      "progress: 63.889%\n",
      "progress: 66.667%\n",
      "progress: 69.444%\n",
      "progress: 72.222%\n",
      "progress: 75.000%\n",
      "progress: 77.778%\n",
      "progress: 80.556%\n",
      "progress: 83.333%\n",
      "progress: 86.111%\n",
      "progress: 88.889%\n",
      "progress: 91.667%\n",
      "progress: 94.444%\n",
      "progress: 97.222%\n"
     ]
    }
   ],
   "source": [
    "load_dir = '/vols/lz/lshanahan/data/numpy/'\n",
    "files = listdir(load_dir)\n",
    "\n",
    "avg_bg = np.load('../fast_2x2_bg.npy')\n",
    "avg_noise = np.load(\"../fast_2x2_noise.npy\")\n",
    "\n",
    "noise = np.stack([io.imread(\"../bg/\"+im) for im in listdir('../bg/')],axis=0)\n",
    "\n",
    "noise = noise[:,::2,::2] + noise[:,1::2,::2] + noise[:,::2,1::2] + noise[:,1::2,1::2]\n",
    "\n",
    "for i in range(int(len(files)/3)): # there are [data,labels,energies] in folder so /3\n",
    "    \n",
    "    im_stack = np.load(f'{load_dir}/data_{i}.npy')/20\n",
    "    \n",
    "    noise_i = np.random.randint(0,1000,len(im_stack))\n",
    "    noise_x = np.random.randint(0,392,len(im_stack))\n",
    "    noise_y = np.random.randint(0,392,len(im_stack))\n",
    "\n",
    "\n",
    "    noise_train = np.stack([noise[noise_i[j], noise_x[j]:noise_x[j]+184, noise_y[j]:noise_y[j]+184] for j in range(len(noise_i))],axis=0)\n",
    "\n",
    "    noise_train_2 = np.stack([noise[noise_i[j], noise_x[j]:noise_x[j]+184, noise_y[j]:noise_y[j]+184] - \\\n",
    "                              avg_bg[noise_x[j]:noise_x[j]+184, noise_y[j]:noise_y[j]+184] for j in range(len(noise_i))],axis=0)\n",
    "\n",
    "    noise_train_3 = np.stack([(noise[noise_i[j], noise_x[j]:noise_x[j]+184, noise_y[j]:noise_y[j]+184] - \\\n",
    "                              avg_bg[noise_x[j]:noise_x[j]+184, noise_y[j]:noise_y[j]+184]) / \\\n",
    "                              avg_noise[noise_x[j]:noise_x[j]+184, noise_y[j]:noise_y[j]+184] for j in range(len(noise_i))],axis=0)\n",
    "\n",
    "\n",
    "    im_stack_1 = im_stack + noise_train\n",
    "    im_stack_2 = im_stack + noise_train_2\n",
    "    im_stack_3 = im_stack + noise_train_3\n",
    "\n",
    "    im_stack_4 = im_stack_2.copy()\n",
    "    im_stack_4[im_stack_4 < 0] = -np.sqrt(np.abs(im_stack_4[im_stack_4 < 0]))\n",
    "    im_stack_4[im_stack_4 > 0] = np.sqrt(im_stack_4[im_stack_4 > 0])\n",
    "\n",
    "    np.save(f'../data/numpy_noise/data_{i}_noise.npy',im_stack_1)\n",
    "    np.save(f'../data/numpy_noise/data_{i}_noise_sub_bg.npy',im_stack_2)\n",
    "    np.save(f'../data/numpy_noise/data_{i}_noise_sqrt_sub_bg.npy',im_stack_4)\n",
    "\n",
    "    del im_stack_1, im_stack_2, im_stack_4\n",
    "\n",
    "\n",
    "    for k in np.arange(0,5.1,1):\n",
    "        im_stack_3[im_stack_3 < k] = 0 \n",
    "        np.save(f'../data/numpy_noise/data_{i}_noise_{k}_threshold.npy',im_stack_3)\n",
    "        \n",
    "    print(f'progress: {(100*i/(len(files)/3)):.3f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from os import listdir\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[24, 19, 17, 8, 11, 33, 29, 15, 2, 26, 21, 7, 9, 22, 18, 34, 25, 10, 30, 20, 27, 31, 35, 12, 6, 16, 3, 23, 5, 0, 13, 14, 1, 32, 4, 28]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[16, 3, 23, 5, 0, 13, 14, 1, 32, 4, 28]"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_nums = list(range(36))\n",
    "np.random.shuffle(file_nums)\n",
    "print(file_nums)\n",
    "\n",
    "file_nums[:25]\n",
    "file_nums[25:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_gen(file_nums, load_dir = '/vols/lz/lshanahan/data/numpy/'):\n",
    "    for i in file_nums: \n",
    "        data = np.expand_dims(np.load(f'{load_dir}/data_{i}.npy'),-1)\n",
    "        labels = np.load(f'{load_dir}/labels_{i}.npy').astype(np.int32)\n",
    "        for j in range(len(labels)):\n",
    "            yield data[j], labels[j:j+1]\n",
    "            \n",
    "# def data_gen_test(file_nums, split, load_dir = '/vols/lz/lshanahan/data/numpy/'):\n",
    "#     files = listdir(load_dir)\n",
    "#     for i in file_nums[split:]: # there are [data,labels,energies] in folder so /\n",
    "#         data = np.expand_dims(np.load(f'{load_dir}/data_{i}.npy'),-1)\n",
    "#         labels = np.load(f'{load_dir}/labels_{i}.npy').astype(np.int32)\n",
    "#         for j in range(len(labels)):\n",
    "#             yield data[j], labels[j:j+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dg = data_gen()\n",
    "# for i in dg:\n",
    "#     print(i[0].shape, i[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_nums = list(range(36))\n",
    "np.random.shuffle(file_nums)\n",
    "split = 25\n",
    "train_dataset = tf.data.Dataset.from_generator(data_gen, \n",
    "                                        args = (file_nums[:split]),\n",
    "                                        output_shapes=(tf.TensorShape((184,184,1)),tf.TensorShape(1)), \n",
    "                                        output_types=(tf.float64,tf.int32))\n",
    "\n",
    "train_data_batch = train_dataset.batch(50)\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_generator(data_gen, \n",
    "                                        args = (file_nums[split:]),\n",
    "                                        output_shapes=(tf.TensorShape((184,184,1)),tf.TensorShape(1)), \n",
    "                                        output_types=(tf.float64,tf.int32))\n",
    "\n",
    "test_data_batch = test_dataset.batch(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorSpec(shape=(None, 184, 184, 1), dtype=tf.float64, name=None),\n",
       " TensorSpec(shape=(None, 1), dtype=tf.int32, name=None))"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_batch.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorSpec(shape=(None, 184, 184, 1), dtype=tf.float64, name=None),\n",
       " TensorSpec(shape=(None, 1), dtype=tf.int32, name=None))"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_batch.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense, Conv2D, MaxPooling2D, LeakyReLU, Dropout\n",
    "\n",
    "def opt_model():\n",
    "    global file_type_list\n",
    "    opt_model = Sequential([\n",
    "        Conv2D(10, kernel_size=(3,3), input_shape=(184,184,1), padding='same'),\n",
    "        LeakyReLU(),\n",
    "        MaxPooling2D(),\n",
    "        Conv2D(30, kernel_size=(3,3), padding='same'),\n",
    "        LeakyReLU(),\n",
    "        MaxPooling2D(),\n",
    "        Conv2D(30, kernel_size=(3,3), padding='same'),\n",
    "        LeakyReLU(),\n",
    "        MaxPooling2D(),\n",
    "        Flatten(),\n",
    "        Dropout(0.05),\n",
    "        Dense(20, kernel_regularizer = tf.keras.regularizers.L1L2(0.05,0.1)),\n",
    "        LeakyReLU(),\n",
    "        Dropout(0.05),\n",
    "        Dense(10, kernel_regularizer = tf.keras.regularizers.L1L2(0.05,0.1)),\n",
    "        LeakyReLU(),\n",
    "        Dense(1, activation='sigmoid'),\n",
    "    ], name='opt_model')\n",
    "    return opt_model\n",
    "\n",
    "model = opt_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"opt_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_81 (Conv2D)           (None, 184, 184, 10)      100       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_135 (LeakyReLU)  (None, 184, 184, 10)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_81 (MaxPooling (None, 92, 92, 10)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_82 (Conv2D)           (None, 92, 92, 30)        2730      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_136 (LeakyReLU)  (None, 92, 92, 30)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_82 (MaxPooling (None, 46, 46, 30)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_83 (Conv2D)           (None, 46, 46, 30)        8130      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_137 (LeakyReLU)  (None, 46, 46, 30)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_83 (MaxPooling (None, 23, 23, 30)        0         \n",
      "_________________________________________________________________\n",
      "flatten_27 (Flatten)         (None, 15870)             0         \n",
      "_________________________________________________________________\n",
      "dropout_54 (Dropout)         (None, 15870)             0         \n",
      "_________________________________________________________________\n",
      "dense_81 (Dense)             (None, 20)                317420    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_138 (LeakyReLU)  (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "dropout_55 (Dropout)         (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "dense_82 (Dense)             (None, 10)                210       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_139 (LeakyReLU)  (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_83 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 328,601\n",
      "Trainable params: 328,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1500/1500 [==============================] - 61s 40ms/step - loss: 39.9535 - accuracy: 0.6709 - val_loss: 5.0632 - val_accuracy: 0.7447\n",
      "Epoch 2/150\n",
      "1500/1500 [==============================] - 60s 40ms/step - loss: 4.7616 - accuracy: 0.7366 - val_loss: 3.9031 - val_accuracy: 0.7530\n",
      "Epoch 3/150\n",
      "1500/1500 [==============================] - 60s 40ms/step - loss: 3.5871 - accuracy: 0.7478 - val_loss: 2.8604 - val_accuracy: 0.7560\n",
      "Epoch 4/150\n",
      "1500/1500 [==============================] - 60s 40ms/step - loss: 2.7551 - accuracy: 0.7574 - val_loss: 2.3376 - val_accuracy: 0.7720\n",
      "Epoch 5/150\n",
      "1500/1500 [==============================] - 60s 40ms/step - loss: 2.3747 - accuracy: 0.7588 - val_loss: 2.2624 - val_accuracy: 0.7802\n",
      "Epoch 6/150\n",
      "1500/1500 [==============================] - 60s 40ms/step - loss: 2.3091 - accuracy: 0.7766 - val_loss: 2.2974 - val_accuracy: 0.7892\n",
      "Epoch 7/150\n",
      "1500/1500 [==============================] - 60s 40ms/step - loss: 2.3312 - accuracy: 0.7954 - val_loss: 2.3440 - val_accuracy: 0.8171\n",
      "Epoch 8/150\n",
      "1500/1500 [==============================] - 60s 40ms/step - loss: 2.3328 - accuracy: 0.8101 - val_loss: 2.3312 - val_accuracy: 0.8314\n",
      "Epoch 9/150\n",
      "1500/1500 [==============================] - 60s 40ms/step - loss: 2.3471 - accuracy: 0.8194 - val_loss: 2.2588 - val_accuracy: 0.8316\n",
      "Epoch 10/150\n",
      "1500/1500 [==============================] - 59s 39ms/step - loss: 2.3058 - accuracy: 0.8246 - val_loss: 2.2870 - val_accuracy: 0.8344\n",
      "Epoch 11/150\n",
      "1500/1500 [==============================] - 59s 39ms/step - loss: 2.3153 - accuracy: 0.8316 - val_loss: 2.2679 - val_accuracy: 0.8396\n",
      "Epoch 12/150\n",
      "1500/1500 [==============================] - 60s 40ms/step - loss: 2.3014 - accuracy: 0.8337 - val_loss: 2.2385 - val_accuracy: 0.8441\n",
      "Epoch 13/150\n",
      "1500/1500 [==============================] - 59s 39ms/step - loss: 2.2918 - accuracy: 0.8345 - val_loss: 2.2454 - val_accuracy: 0.8448\n",
      "Epoch 14/150\n",
      "1500/1500 [==============================] - 59s 39ms/step - loss: 2.2837 - accuracy: 0.8378 - val_loss: 2.2665 - val_accuracy: 0.8500\n",
      "Epoch 15/150\n",
      "1500/1500 [==============================] - 59s 39ms/step - loss: 2.2711 - accuracy: 0.8383 - val_loss: 2.2315 - val_accuracy: 0.8499\n",
      "Epoch 16/150\n",
      "1500/1500 [==============================] - 59s 39ms/step - loss: 2.2863 - accuracy: 0.8408 - val_loss: 2.2480 - val_accuracy: 0.8416\n",
      "Epoch 17/150\n",
      "1500/1500 [==============================] - 59s 39ms/step - loss: 2.2778 - accuracy: 0.8410 - val_loss: 2.3003 - val_accuracy: 0.8301\n",
      "Epoch 18/150\n",
      "1500/1500 [==============================] - 60s 40ms/step - loss: 2.2758 - accuracy: 0.8430 - val_loss: 2.2952 - val_accuracy: 0.8480\n",
      "Epoch 19/150\n",
      "1500/1500 [==============================] - 60s 40ms/step - loss: 2.2848 - accuracy: 0.8408 - val_loss: 2.2564 - val_accuracy: 0.8517\n",
      "Epoch 20/150\n",
      "1500/1500 [==============================] - 60s 40ms/step - loss: 2.2533 - accuracy: 0.8463 - val_loss: 2.2318 - val_accuracy: 0.8516\n",
      "Epoch 21/150\n",
      "1500/1500 [==============================] - 59s 39ms/step - loss: 2.2773 - accuracy: 0.8432 - val_loss: 2.2800 - val_accuracy: 0.8533\n",
      "Epoch 22/150\n",
      "1500/1500 [==============================] - 59s 39ms/step - loss: 2.2797 - accuracy: 0.8456 - val_loss: 2.3053 - val_accuracy: 0.8540\n",
      "Epoch 23/150\n",
      "1500/1500 [==============================] - 59s 39ms/step - loss: 2.2883 - accuracy: 0.8476 - val_loss: 2.3089 - val_accuracy: 0.8574\n",
      "Epoch 24/150\n",
      "1500/1500 [==============================] - 59s 39ms/step - loss: 2.2731 - accuracy: 0.8477 - val_loss: 2.2982 - val_accuracy: 0.8546\n",
      "Epoch 25/150\n",
      "1500/1500 [==============================] - 59s 39ms/step - loss: 2.2590 - accuracy: 0.8491 - val_loss: 2.3044 - val_accuracy: 0.8495\n",
      "Epoch 26/150\n",
      "1500/1500 [==============================] - 59s 39ms/step - loss: 2.2736 - accuracy: 0.8482 - val_loss: 2.3035 - val_accuracy: 0.8557\n",
      "Epoch 27/150\n",
      "1500/1500 [==============================] - 59s 39ms/step - loss: 2.2589 - accuracy: 0.8487 - val_loss: 2.3208 - val_accuracy: 0.8447\n",
      "Epoch 28/150\n",
      "1500/1500 [==============================] - 59s 39ms/step - loss: 2.2578 - accuracy: 0.8496 - val_loss: 2.3361 - val_accuracy: 0.8505\n",
      "Epoch 29/150\n",
      "1500/1500 [==============================] - 60s 40ms/step - loss: 2.2672 - accuracy: 0.8519 - val_loss: 2.2695 - val_accuracy: 0.8592\n",
      "Epoch 30/150\n",
      "1500/1500 [==============================] - 60s 40ms/step - loss: 2.2454 - accuracy: 0.8516 - val_loss: 2.4161 - val_accuracy: 0.8395\n",
      "Epoch 31/150\n",
      "1500/1500 [==============================] - 60s 40ms/step - loss: 2.2756 - accuracy: 0.8519 - val_loss: 2.3142 - val_accuracy: 0.8574\n",
      "Epoch 32/150\n",
      "1500/1500 [==============================] - 59s 39ms/step - loss: 2.2619 - accuracy: 0.8520 - val_loss: 2.2977 - val_accuracy: 0.8509\n",
      "Epoch 33/150\n",
      "1500/1500 [==============================] - 59s 39ms/step - loss: 2.2602 - accuracy: 0.8528 - val_loss: 2.2885 - val_accuracy: 0.8561\n",
      "Epoch 34/150\n",
      "1500/1500 [==============================] - 59s 39ms/step - loss: 2.2651 - accuracy: 0.8532 - val_loss: 2.2953 - val_accuracy: 0.8549\n",
      "Epoch 35/150\n",
      "1500/1500 [==============================] - 59s 39ms/step - loss: 2.2686 - accuracy: 0.8535 - val_loss: 2.3118 - val_accuracy: 0.8462\n",
      "Epoch 36/150\n",
      "1500/1500 [==============================] - 59s 39ms/step - loss: 2.2607 - accuracy: 0.8540 - val_loss: 2.3105 - val_accuracy: 0.8568\n",
      "Epoch 37/150\n",
      "1500/1500 [==============================] - 59s 39ms/step - loss: 2.2656 - accuracy: 0.8524 - val_loss: 2.4059 - val_accuracy: 0.8498\n",
      "Epoch 38/150\n",
      "1500/1500 [==============================] - 59s 39ms/step - loss: 2.2725 - accuracy: 0.8538 - val_loss: 2.3235 - val_accuracy: 0.8517\n",
      "Epoch 39/150\n",
      "1500/1500 [==============================] - 60s 40ms/step - loss: 2.2630 - accuracy: 0.8547 - val_loss: 2.3210 - val_accuracy: 0.8581\n",
      "Epoch 40/150\n",
      "1500/1500 [==============================] - 59s 39ms/step - loss: 2.2716 - accuracy: 0.8545 - val_loss: 2.3312 - val_accuracy: 0.8591\n",
      "Epoch 41/150\n",
      "1500/1500 [==============================] - 59s 39ms/step - loss: 2.2404 - accuracy: 0.8552 - val_loss: 2.3266 - val_accuracy: 0.8543\n",
      "Epoch 42/150\n",
      "1500/1500 [==============================] - 59s 39ms/step - loss: 2.2506 - accuracy: 0.8572 - val_loss: 2.3705 - val_accuracy: 0.8578\n",
      "Epoch 43/150\n",
      "1500/1500 [==============================] - 59s 39ms/step - loss: 2.2641 - accuracy: 0.8584 - val_loss: 2.2909 - val_accuracy: 0.8475\n",
      "Epoch 44/150\n",
      "1500/1500 [==============================] - 59s 39ms/step - loss: 2.2444 - accuracy: 0.8551 - val_loss: 2.3081 - val_accuracy: 0.8629\n",
      "Epoch 45/150\n",
      "1500/1500 [==============================] - 59s 39ms/step - loss: 2.2383 - accuracy: 0.8587 - val_loss: 2.3332 - val_accuracy: 0.8522\n",
      "Epoch 46/150\n",
      "1500/1500 [==============================] - 59s 39ms/step - loss: 2.2459 - accuracy: 0.8583 - val_loss: 2.2685 - val_accuracy: 0.8569\n",
      "Epoch 47/150\n",
      "1500/1500 [==============================] - 59s 39ms/step - loss: 2.2376 - accuracy: 0.8581 - val_loss: 2.3161 - val_accuracy: 0.8510\n",
      "Epoch 48/150\n",
      "1500/1500 [==============================] - 59s 39ms/step - loss: 2.2474 - accuracy: 0.8592 - val_loss: 2.2762 - val_accuracy: 0.8565\n",
      "Epoch 49/150\n",
      "1500/1500 [==============================] - 59s 39ms/step - loss: 2.2288 - accuracy: 0.8599 - val_loss: 2.2337 - val_accuracy: 0.8614\n",
      "Epoch 50/150\n",
      "1500/1500 [==============================] - 59s 39ms/step - loss: 2.2445 - accuracy: 0.8609 - val_loss: 2.2882 - val_accuracy: 0.8560\n",
      "Epoch 51/150\n",
      "1500/1500 [==============================] - 59s 39ms/step - loss: 2.2407 - accuracy: 0.8603 - val_loss: 2.2344 - val_accuracy: 0.8620\n",
      "Epoch 52/150\n",
      "1500/1500 [==============================] - 59s 39ms/step - loss: 2.2312 - accuracy: 0.8591 - val_loss: 2.3274 - val_accuracy: 0.8551\n",
      "Epoch 53/150\n",
      "1500/1500 [==============================] - 59s 39ms/step - loss: 2.2332 - accuracy: 0.8615 - val_loss: 2.2648 - val_accuracy: 0.8550\n",
      "Epoch 54/150\n",
      "1500/1500 [==============================] - 59s 39ms/step - loss: 2.2494 - accuracy: 0.8600 - val_loss: 2.2601 - val_accuracy: 0.8658\n",
      "Epoch 55/150\n",
      "1500/1500 [==============================] - 60s 40ms/step - loss: 2.2327 - accuracy: 0.8603 - val_loss: 2.2641 - val_accuracy: 0.8636\n",
      "Epoch 56/150\n",
      "1500/1500 [==============================] - 59s 39ms/step - loss: 2.2550 - accuracy: 0.8610 - val_loss: 2.2466 - val_accuracy: 0.8676\n",
      "Epoch 57/150\n",
      "1500/1500 [==============================] - 59s 39ms/step - loss: 2.2426 - accuracy: 0.8620 - val_loss: 2.3186 - val_accuracy: 0.8556\n",
      "Epoch 58/150\n",
      "1500/1500 [==============================] - 59s 39ms/step - loss: 2.2523 - accuracy: 0.8607 - val_loss: 2.3417 - val_accuracy: 0.8525\n",
      "Epoch 59/150\n",
      "1500/1500 [==============================] - 60s 40ms/step - loss: 2.2378 - accuracy: 0.8627 - val_loss: 2.2727 - val_accuracy: 0.8504\n",
      "Epoch 60/150\n",
      "1500/1500 [==============================] - 60s 40ms/step - loss: 2.2393 - accuracy: 0.8620 - val_loss: 2.3405 - val_accuracy: 0.8593\n",
      "Epoch 61/150\n",
      "1500/1500 [==============================] - 60s 40ms/step - loss: 2.2418 - accuracy: 0.8613 - val_loss: 2.3153 - val_accuracy: 0.8602\n",
      "Epoch 62/150\n",
      "1500/1500 [==============================] - 59s 39ms/step - loss: 2.2259 - accuracy: 0.8627 - val_loss: 2.2676 - val_accuracy: 0.8635\n",
      "Epoch 63/150\n",
      "1500/1500 [==============================] - 59s 39ms/step - loss: 2.2494 - accuracy: 0.8609 - val_loss: 2.2279 - val_accuracy: 0.8635\n",
      "Epoch 64/150\n",
      "1500/1500 [==============================] - 59s 39ms/step - loss: 2.2439 - accuracy: 0.8622 - val_loss: 2.2439 - val_accuracy: 0.8632\n",
      "Epoch 65/150\n",
      "1500/1500 [==============================] - 60s 40ms/step - loss: 2.2229 - accuracy: 0.8644 - val_loss: 2.2644 - val_accuracy: 0.8601\n",
      "Epoch 66/150\n",
      "1500/1500 [==============================] - 59s 39ms/step - loss: 2.2322 - accuracy: 0.8636 - val_loss: 2.2380 - val_accuracy: 0.8673\n",
      "Epoch 67/150\n",
      "1500/1500 [==============================] - 59s 39ms/step - loss: 2.2316 - accuracy: 0.8649 - val_loss: 2.2124 - val_accuracy: 0.8603\n",
      "Epoch 68/150\n",
      "1500/1500 [==============================] - 59s 39ms/step - loss: 2.2256 - accuracy: 0.8643 - val_loss: 2.2546 - val_accuracy: 0.8677\n",
      "Epoch 69/150\n",
      "1500/1500 [==============================] - 59s 39ms/step - loss: 2.2375 - accuracy: 0.8640 - val_loss: 2.2409 - val_accuracy: 0.8528\n",
      "Epoch 70/150\n",
      "1500/1500 [==============================] - 59s 39ms/step - loss: 2.2287 - accuracy: 0.8641 - val_loss: 2.2200 - val_accuracy: 0.8581\n",
      "Epoch 71/150\n",
      "1500/1500 [==============================] - 59s 39ms/step - loss: 2.2198 - accuracy: 0.8653 - val_loss: 2.3983 - val_accuracy: 0.8616\n",
      "Epoch 72/150\n",
      "1500/1500 [==============================] - 59s 39ms/step - loss: 2.2252 - accuracy: 0.8654 - val_loss: 2.2698 - val_accuracy: 0.8580\n",
      "Epoch 73/150\n",
      "1500/1500 [==============================] - 59s 39ms/step - loss: 2.2166 - accuracy: 0.8650 - val_loss: 2.2787 - val_accuracy: 0.8616\n",
      "Epoch 74/150\n",
      "1500/1500 [==============================] - 60s 40ms/step - loss: 2.2117 - accuracy: 0.8651 - val_loss: 2.3136 - val_accuracy: 0.8664\n",
      "Epoch 75/150\n",
      "1500/1500 [==============================] - 60s 40ms/step - loss: 2.2224 - accuracy: 0.8649 - val_loss: 2.2433 - val_accuracy: 0.8632\n",
      "Epoch 76/150\n",
      "1500/1500 [==============================] - 59s 39ms/step - loss: 2.2187 - accuracy: 0.8641 - val_loss: 2.2133 - val_accuracy: 0.8715\n",
      "Epoch 77/150\n",
      "1500/1500 [==============================] - 59s 39ms/step - loss: 2.2424 - accuracy: 0.8650 - val_loss: 2.2506 - val_accuracy: 0.8669\n",
      "Epoch 78/150\n",
      "1500/1500 [==============================] - 59s 39ms/step - loss: 2.2225 - accuracy: 0.8656 - val_loss: 2.4321 - val_accuracy: 0.8626\n",
      "Epoch 79/150\n",
      "1500/1500 [==============================] - 59s 39ms/step - loss: 2.2477 - accuracy: 0.8655 - val_loss: 2.2293 - val_accuracy: 0.8694\n",
      "Epoch 80/150\n",
      "1500/1500 [==============================] - 60s 40ms/step - loss: 2.2241 - accuracy: 0.8681 - val_loss: 2.2478 - val_accuracy: 0.8610\n",
      "Epoch 81/150\n",
      "1500/1500 [==============================] - 59s 39ms/step - loss: 2.2220 - accuracy: 0.8652 - val_loss: 2.3858 - val_accuracy: 0.8625\n",
      "Epoch 82/150\n",
      "1500/1500 [==============================] - 59s 39ms/step - loss: 2.2289 - accuracy: 0.8685 - val_loss: 2.1999 - val_accuracy: 0.8672\n",
      "Epoch 83/150\n",
      "1500/1500 [==============================] - 59s 39ms/step - loss: 2.2156 - accuracy: 0.8675 - val_loss: 2.2347 - val_accuracy: 0.8655\n",
      "Epoch 84/150\n",
      "1500/1500 [==============================] - 59s 39ms/step - loss: 2.2250 - accuracy: 0.8662 - val_loss: 2.3387 - val_accuracy: 0.8687\n",
      "Epoch 85/150\n",
      "1500/1500 [==============================] - 60s 40ms/step - loss: 2.2583 - accuracy: 0.8668 - val_loss: 2.3497 - val_accuracy: 0.8621\n",
      "Epoch 86/150\n",
      "1500/1500 [==============================] - 59s 39ms/step - loss: 2.2303 - accuracy: 0.8670 - val_loss: 2.2512 - val_accuracy: 0.8622\n",
      "Epoch 87/150\n",
      "1500/1500 [==============================] - 59s 39ms/step - loss: 2.2314 - accuracy: 0.8673 - val_loss: 2.3918 - val_accuracy: 0.8660\n",
      "Epoch 88/150\n",
      "1500/1500 [==============================] - 59s 39ms/step - loss: 2.2339 - accuracy: 0.8694 - val_loss: 2.3024 - val_accuracy: 0.8651\n",
      "Epoch 89/150\n",
      "1500/1500 [==============================] - 59s 39ms/step - loss: 2.2231 - accuracy: 0.8674 - val_loss: 2.2692 - val_accuracy: 0.8701\n",
      "Epoch 90/150\n",
      "1500/1500 [==============================] - 60s 40ms/step - loss: 2.2337 - accuracy: 0.8704 - val_loss: 2.2782 - val_accuracy: 0.8618\n",
      "Epoch 91/150\n",
      "1500/1500 [==============================] - 59s 39ms/step - loss: 2.2187 - accuracy: 0.8678 - val_loss: 2.3554 - val_accuracy: 0.8704\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f1378ec3610>"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', restore_best_weights=True, patience=15)\n",
    "\n",
    "model = opt_model()\n",
    "\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=opt, loss='binary_crossentropy',metrics=['accuracy'])\n",
    "model.fit(train_data_batch, epochs=150, validation_data=test_data_batch,callbacks=[callback],\\\n",
    "         verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('tiff_mod_1.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Split generated data into train and test sets\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
